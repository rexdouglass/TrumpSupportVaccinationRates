---
title: "What explains U.S. Covid-19 Vaccination Rates? A Machine Learning Workflow for County Level Ecological Inference"
author: "Rex W. Douglass"
output:
  html_notebook
editor_options: 
  markdown: 
    wrap: 72
bibliography: WhatExplainsUSCovid19VaccinationRates.bib
---


# The Outcome



Placebos - what other left hand side things can we put in there? Quote
chadoins wto paper.

<https://fivethirtyeight.com/features/the-extremes-of-the-gop-have-moved-beyond-fox-news/>

<https://www.prri.org/research/prri-ifyc-covid-vaccine-religion-report/>

```{r}
fromscratch=F

setwd("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/")


#knitr::opts_chunk$set(fig.width = 8, fig.height = 8, message=F, warning=F, echo=F, results=F)

#Library Loads
library(pacman)
p_load(tidyverse)
p_load(janitor)
p_load(tidylog)
p_load(stringr)
p_load(ggdag)
p_load(data.table)
p_load(sf)
p_load(glue)
options(tigris_use_cache = TRUE)
```

# Introduction

What explains vaccine uptake across counties in the US? The answer to
this question has important implications for understanding and planning
for the future course of the pandemic as pockets with low uptake become
hotspots for future waves and especially future variants.

# Literature

<https://www.medrxiv.org/content/10.1101/2021.05.28.21257946v1>

<https://www.cjonline.com/story/news/coronavirus/2021/02/19/kansas-plots-fix-problems-covid-19-vaccine-data-reporting/4507251001/>

# Step 1: Form Reasonable Prior Beliefs

You may have seen [pairwise correlation
plots](https://twitter.com/PollsAndVotes/status/1404667067392053248)
that posit a data generating process of uptake like this.

Presidential vote is used in other projects attempting to estimate
county level vaccination rates.
(<https://www.norc.org/PDFs/NIS/Seeskin_Estimating%20County%20Level%20Vaccination%20Coverage_2020.pdf>)

```{r}
#+ Education + MedicalResources
bigger_dag4 <- dagify(
                     Uptake ~ Supply + Demmand + Measurement,
                     Supply ~ HealthResources + Economy + Urbanicity + HealthConditions + Geography + Age,
                     Demmand ~ Race + Education + Politics + Covid + HealthResources + Age + Economy + Urbanicity + VaccineBeliefs + HealthConditions + Mobility,
                     Masking ~ Demmand
                     )
#dag_paths(bigger_dag)  
#ggdag_paths(bigger_dag)
#ggdag_adjustment_set(bigger_dag4, text = FALSE, use_labels = "label", shadow = TRUE)

p <- bigger_dag4 %>% 
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_dag_point(col="lightblue") +
    #geom_dag_edges_arc() +
    geom_dag_edges(label_colour = "black") +
    geom_dag_text(col = "black") +
    theme_dag() 

```

```{r, results=T, fig.width = 10, fig.height = 10}
p
```

```{r}

dag1 <- dagify(Uptake ~~ TrumpVote)
#dag_paths(bigger_dag)  
#ggdag_paths(bigger_dag)

p <- dag1 %>% 
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_dag_point(col="lightblue") +
    geom_dag_edges(label_colour = "black") +
    geom_dag_text(col = "black") +
    theme_dag() #+
    #theme(plot.margin=unit(c(0,0,0,0),"cm")) #  +
    #expand_limits(y = c(1, 1), x = c(1, 1))

```

```{r, results=T, fig.width = 8, fig.height = 2}
p
```

Others have [started to
posit](https://tompepinsky.com/2021/06/24/trump-support-and-vaccination-rates-some-hypotheses-and-some-data/)
a multivariate data generating process of vaccine uptake that is a
linear function of a county's demographic characteristics, urbanity, and
recent presidential vote choices.

```{r}

bigger_dag <- dagify(Uptake ~ TrumpVote + TrumpSwing + Demographics + Rural)
#dag_paths(bigger_dag)  
#ggdag_paths(bigger_dag)

p <- bigger_dag %>% 
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_dag_point(col="lightblue") +
    geom_dag_edges(label_colour = "black") +
    geom_dag_text(col = "black") +
    theme_dag()

```

```{r, results=T, fig.width = 8, fig.height = 6}
p
```

This DGP is better in that it considers additional factors, but it is
still an unlikely and incomplete data generating process where TrumpVote
is exogenous to demographic and urbanity characteristics of a county.
Worse, some of the features are mechanically related to one another,
e.g. Log-Population and Rural are included in the same model despite
being functions of one another. Likewise TrumpVote and TrumpUpswing are
also mechanically related, a county with a 100% swing necessarily has a
100% Trump Vote with a nonlinear function for every other permutation.
Drawing the DGP with these additional elements quickly starts to become
untenable below.

```{r}
#+ Education + MedicalResources
bigger_dag2 <- dagify(
                     Uptake ~ TrumpVote + TrumpSwing + Demographics + Rural, 
                     TrumpVote ~ Demographics+ Rural,
                     TrumpSwing ~ Demographics + Rural,
                     TrumpVote ~ TrumpSwing,
                     TrumpSwing  ~~ TrumpVote,
                     Demographics ~~ Rural
                     )
#dag_paths(bigger_dag)  
#ggdag_paths(bigger_dag)

p <- bigger_dag2 %>% 
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_dag_point(col="lightblue") +
    #geom_dag_edges_arc() +
    geom_dag_edges(label_colour = "black") +
    geom_dag_text(col = "black") +
    theme_dag() 

```

```{r, results=T, fig.width = 10, fig.height = 10}
p
```

### Unit of Analysis

State vs County vs zip code 

### The Vacination Process

Vaccinations began on December 14, 2020.
<https://www.hhs.gov/coronavirus/covid-19-vaccines/distribution/index.html>

"The COVID-19 vaccine supply has increased to the point that DSHS will
no longer allocate vaccine to providers each week. As of May 10,
providers can order vaccine from DSHS on a daily basis. The tables on
this page reflect allocations that were made between Dec. 14, 2020 --
May 3,2021."
<https://www.dshs.state.tx.us/coronavirus/immunize/vaccineallocations.aspx>

Not to pile on to an already catastrophic causal inference problem, but
the course of the pandemic (say in terms of per capita deaths) likely
impacted voting decisions and then later vaccine uptake, and education
impacted both as well. An example of the kind of graph we could draw
including those components is below. In particular, it necessarily
includes demographic characteristics like age percentiles because they
were an explicit part of the phased Vaccine rollout process and also
strongly relate to vote outcomes.

Phase 1a Healthcare Personnel and Long-term care facility residents
Phase 1b Frontline Essential workers, a\>75 Phace 1c Persons aged 65-74,
High Risk Medical Conditions Essential Workers

<https://aspe.hhs.gov/system/files/pdf/265516/vaccine-administration-brief.pdf>
"As of February 22, 2021, the 50 states and D.C. had administered an
average of 86.2% of their received vaccine doses. However, variability
between states was considerable, with administration rates ranging from
72.9% (District of Columbia) to 99.8% (New Mexico)."

"One notable outlier is Alaska, which has launched a highly successful
vaccination campaign.16 Alaska's data on administration rates is not
directly comparable to other states because it receives allocations
monthly instead of weekly due to the unique challenges of"

Many hypotheses have emerged to explain differences in vaccine
administration rates between states.18,19 Potential predictors include
state population size, size of the vaccine eligible population,
centralization or decentralization of vaccine scheduling systems,
vaccination site density, and local attitudes toward vaccines.

<https://data.cdc.gov/Vaccinations/COVID-19-Vaccine-Distribution-Allocations-by-Juris/b7pe-5nws>
Vaccine allocations on a per-capita basis on relatively uniform, with
the exception of outlying territories and Alaska because of
transportation issues.

```{r}
#+ Education + MedicalResources
bigger_dag3 <- dagify(
                     Uptake ~ TrumpVote + TrumpSwing + Demographics + Rural + Education + DeathsPerCap + Age + Wealth + HealthResources, 
                     TrumpVote ~ Demographics + Rural + Education + DeathsPerCap + Age,
                     TrumpSwing ~ Demographics + Rural + Education + DeathsPerCap + Age,
                     TrumpVote ~ TrumpSwing,
                     TrumpSwing  ~~ TrumpVote,
                     Demographics ~~ Rural,
                     DeathsPerCap ~ Demographics + Rural + Education  + Age + HealthResources + Wealth,
                     Education ~ Age,
                     HealthResources ~ Wealth
                     )
#dag_paths(bigger_dag)  
#ggdag_paths(bigger_dag)

p <- bigger_dag3 %>% 
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_dag_point(col="lightblue") +
    #geom_dag_edges_arc() +
    geom_dag_edges(label_colour = "black") +
    geom_dag_text(col = "black") +
    theme_dag() 

```

```{r, results=T, fig.width = 10, fig.height = 10}
p
```

In sum, the simplest toy causal diagram is outside of the reach of a
single linear model. Any individual parameter from a model fit to only a
subset of these paths is not an estimate of the causal estimand.
Further, there are only about 3000 counties worth the datapoints to
disentangle this mess, and those counties are auto-correlated in lots of
ways not taken into account here which further reduces the unique
information available.

# Literature/RHS/ Data Generating Processes

We consider a data generating process for reported vaccine uptake that is a function of vaccine demand, vaccine supply, and institutional reporting mechanisms. 

Vaccine demand is defined here as the number of vaccines that would be administered given unconstrained supply. When supply is constrained in any way, or imperfectly measured, then demand is only partially observed to be at least as much as the given supply but possibly much higher. Likewise, vaccine supply is defined here as the number of vaccines that would be administered given unconstrained demand. With perfect demand and measurement, any unused vaccines provide an upper bound on possible demand. Institutional reporting mechanisms are the process by which actual vaccine uptake is mapped into publicly reported records. As demonstrated above, institutional measurement error of health outcomes has systematic nonrandom sources of error. In some cases those systematic components may be an even larger part of the data generating process than the underlying empirical data generating process we actually care about.

# Demand

The most proximate measure of demand available is survey self reported desire to receive a vaccine. COVID-19 Trends and Impact Survey (CTIS) run by the Delphi group at Carnegie Mellon [@barkayWeightsMethodologyBrief2020]
We propose to measure demand most directly with survey questions of self reported desire for a vaccination. 







typically referred to as vaccine hesitancy,

[@truongWhatFactorsPromote2021]

[@pittsHealthLiteracyCommon2021]


```{r, eval=F}

#Doesn't have the vaccine questions
#fb <- fread("/mnt/8tb_a/rwd_github_private/cleancovidcounts/data_temp/CMU US symptom survey aggregates/overall-county-smoothed.csv")


p_load(covidcast)
p_load(dplyr)

#So this is have been, have an appointment to, or want to
#smoothed_wcovid_vaccinated_appointment_or_accept	Estimated percentage of respondents who either have already received a COVID vaccine or have an appointment to get a COVID vaccine or would definitely or probably choose to get #vaccinated, if a vaccine were offered to them today.
#Earliest date available: 2021-05-19
smoothed_waccept_covid_vaccine <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_waccept_covid_vaccine"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))
table(smoothed_waccept_covid_vaccine$geo_value) %>% length() #only available for 757 counties


#smoothed_wappointment_or_accept_covid_vaccine	Estimated percentage of respondents who either have an appointment to get a COVID-19 vaccine or would definitely or probably choose to get vaccinated, if a vaccine were offered to them #today, among respondents who have not yet been vaccinated.
#Earliest date available: 2021-05-19
smoothed_wappointment_or_accept_covid_vaccine <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wappointment_or_accept_covid_vaccine"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_waccept_covid_vaccine_no_appointment	Estimated percentage of respondents who would definitely or probably choose to get vaccinated, if a vaccine were offered to them today, among respondents who have not yet been #vaccinated and do not have an appointment to do so.
#Earliest date available: 2021-05-19
smoothed_waccept_covid_vaccine_no_appointment <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_waccept_covid_vaccine_no_appointment"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wvaccinate_children	Estimated percentage of respondents with children who report that they will definitely or probably get the vaccine for their children.
#Earliest date available: 2021-06-10
smoothed_wvaccinate_children <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccinate_children"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#Rex
#This looks like smoothed_waccept_covid_vaccine, and the reason it drops is because it changes from everyone to just those who haven't yet
#smoothed_waccept_covid_vaccine	Discontinued as of Wave 11, May 19, 2021 Estimated percentage of respondents who would definitely or probably choose to get vaccinated, if a COVID-19 vaccine were offered to them today. Note: Until #January 6, 2021, all respondents answered this question; beginning on that date, only respondents who said they have not received a COVID vaccine are asked this question.
#Earliest date available: 2021-01-01
smoothed_waccept_covid_vaccine <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_waccept_covid_vaccine"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wcovid_vaccinated	Estimated percentage of respondents who have already received a vaccine for COVID-19. Note: The Centers for Disease Control compiles data on vaccine administration across the United States. This signal #may differ from CDC data because of survey biases and should not be treated as authoritative. However, the survey signal is not subject to the lags and reporting problems in official vaccination data.
#Earliest date available: 2021-01-06
smoothed_wcovid_vaccinated <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wcovid_vaccinated"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wappointment_not_vaccinated	Estimated percentage of respondents who have an appointment to get a COVID-19 vaccine, among respondents who have not yet been vaccinated.
#Earliest date available: 2021-05-19
smoothed_wappointment_not_vaccinated <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wappointment_not_vaccinated"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wreceived_2_vaccine_doses	Estimated percentage of respondents who have received two doses of a COVID-19 vaccine, among respondents who have received either one or two doses of a COVID-19 vaccine. This item was shown to #respondents starting in Wave 7.
#Earliest date available: 2021-02-06
smoothed_wreceived_2_vaccine_doses <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wreceived_2_vaccine_doses"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#These are recent
#smoothed_wvaccine_barrier_eligible	Estimated percentage of respondents who report eligibility requirements as a barrier to getting the vaccine, among those who have already been vaccinated or have tried to get vaccinated.
#Earliest date available: 2021-06-10
smoothed_wvaccine_barrier_eligible <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccine_barrier_eligible"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))
table(smoothed_wvaccine_barrier_eligible$geo_value) %>% length() #only available for 369 counties

#smoothed_wvaccine_barrier_no_appointments	Estimated percentage of respondents who report lack of vaccine or vaccine appointments as a barrier to getting the vaccine, among those who have already been vaccinated or have tried to #get vaccinated.
#Earliest date available: 2021-06-10
smoothed_wvaccine_barrier_no_appointments <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccine_barrier_no_appointments"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))
table(smoothed_wvaccine_barrier_no_appointments$geo_value) %>% length() #only available for 369 counties


#smoothed_wvaccine_barrier_appointment_time	Estimated percentage of respondents who report available appointment times as a barrier to getting the vaccine, among those who have already been vaccinated or have tried to get #vaccinated.
#Earliest date available: 2021-06-10
smoothed_wvaccine_barrier_appointment_time <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccine_barrier_appointment_time"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wvaccine_barrier_technical_difficulties	Estimated percentage of respondents who report technical difficulties with the website or phone line as a barrier to getting the vaccine, among those who have already been #vaccinated or have tried to get vaccinated.
#Earliest date available: 2021-06-10
smoothed_wvaccine_barrier_technical_difficulties <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccine_barrier_technical_difficulties"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wvaccine_barrier_document	Estimated percentage of respondents who report inability to provide required documents as a barrier to getting the vaccine, among those who have already been vaccinated or have tried to get vaccinated.
#Earliest date available: 2021-06-10
smoothed_wvaccine_barrier_document <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccine_barrier_document"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wvaccine_barrier_technology_access	Estimated percentage of respondents who report limited access to internet or phone as a barrier to getting the vaccine, among those who have already been vaccinated or have tried to get vaccinated.
#Earliest date available: 2021-06-10
smoothed_wvaccine_barrier_technology_access <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccine_barrier_technology_access"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wvaccine_barrier_travel	Estimated percentage of respondents who report difficulty traveling to vaccination sites as a barrier to getting the vaccine, among those who have already been vaccinated or have tried to get vaccinated.
#Earliest date available: 2021-06-10
smoothed_wvaccine_barrier_travel <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccine_barrier_travel"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))
table(smoothed_wvaccine_barrier_travel$geo_value) %>% length() 

#smoothed_wvaccine_barrier_language	Estimated percentage of respondents who report information not being available in their native language as a barrier to getting the vaccine, among those who have already been vaccinated or have tried to get vaccinated.
#Earliest date available: 2021-06-10
smoothed_wvaccine_barrier_language <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccine_barrier_language"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wvaccine_barrier_childcare	Estimated percentage of respondents who report lack of childcare as a barrier to getting the vaccine, among those who have already been vaccinated or have tried to get vaccinated.
#Earliest date available: 2021-06-10
smoothed_wvaccine_barrier_childcare <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccine_barrier_childcare"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wvaccine_barrier_time	Estimated percentage of respondents who report difficulty getting time away from work or school as a barrier to getting the vaccine, among those who have already been vaccinated or have tried to get vaccinated.
#Earliest date available: 2021-06-10
smoothed_wvaccine_barrier_time <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccine_barrier_time"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wvaccine_barrier_type	Estimated percentage of respondents who report available vaccine type as a barrier to getting the vaccine, among those who have already been vaccinated or have tried to get vaccinated.
#Earliest date available: 2021-06-10
smoothed_wvaccine_barrier_type <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccine_barrier_type"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wvaccine_barrier_none	Estimated percentage of respondents who report experiencing none of the listed barriers to gettint the vaccing, among those who have already been vaccinated or have tried to get vaccinated.
#Earliest date available: 2021-06-10
smoothed_wvaccine_barrier_none	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccine_barrier_none	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wworried_vaccine_side_effects	Estimated percentage of respondents who are very or moderately concerned that they would “experience a side effect from a COVID-19 vaccination.” Note: Until March 2, 2021, all respondents answered this question, including those who had already received one or more doses of a COVID-19 vaccine; beginning on that date, only respondents who said they have not received a COVID vaccine are asked this question.
#Earliest date available: 2021-01-12
smoothed_wworried_vaccine_side_effects	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wworried_vaccine_side_effects	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_whesitancy_reason_sideeffects	Estimated percentage of respondents who say they are hesitant to get vaccinated because they are worried about side effects, among respondents who answered “Yes, probably”, “No, probably not”, or “No, definitely not” when asked if they would get vaccinated if offered (item V3). This series of items was shown to respondents starting in Wave 8.
#Earliest date available: 2021-02-26
smoothed_whesitancy_reason_sideeffects	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_whesitancy_reason_sideeffects	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_whesitancy_reason_allergic	Discontinued as of Wave 11, May 19, 2021 Estimated percentage of respondents who say they are hesitant to get vaccinated because they are worried about having an allergic reaction, among respondents who answered “Yes, probably”, “No, probably not”, or “No, definitely not” when asked if they would get vaccinated if offered (item V3). This series of items was shown to respondents starting in Wave 8.
#Earliest date available: 2021-02-26
smoothed_whesitancy_reason_allergic	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_whesitancy_reason_allergic	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_whesitancy_reason_ineffective	Estimated percentage of respondents who say they are hesitant to get vaccinated because they don’t know if a COVID-19 vaccine will work, among respondents who answered “Yes, probably”, “No, probably not”, or “No, definitely not” when asked if they would get vaccinated if offered (item V3). This series of items was shown to respondents starting in Wave 8.
#Earliest date available: 2021-02-26
smoothed_whesitancy_reason_ineffective	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_whesitancy_reason_ineffective	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_whesitancy_reason_unnecessary	Estimated percentage of respondents who say they are hesitant to get vaccinated because they don’t believe they need a COVID-19 vaccine, among respondents who answered “Yes, probably”, “No, probably not”, or “No, definitely not” when asked if they would get vaccinated if offered (item V3). This series of items was shown to respondents starting in Wave 8.
#Earliest date available: 2021-02-26
smoothed_whesitancy_reason_unnecessary	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_whesitancy_reason_unnecessary	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_whesitancy_reason_dislike_vaccines	Estimated percentage of respondents who say they are hesitant to get vaccinated because they dislike vaccines, among respondents who answered “Yes, probably”, “No, probably not”, or “No, definitely not” when asked if they would get vaccinated if offered (item V3). This series of items was shown to respondents starting in Wave 8.
#Earliest date available: 2021-02-26
smoothed_whesitancy_reason_dislike_vaccines	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_whesitancy_reason_dislike_vaccines	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_whesitancy_reason_not_recommended	Discontinued as of Wave 11, May 19, 2021 Estimated percentage of respondents who say they are hesitant to get vaccinated because their doctor did not recommend it, among respondents who answered “Yes, probably”, “No, probably not”, or “No, definitely not” when asked if they would get vaccinated if offered (item V3). This series of items was shown to respondents starting in Wave 8.
#Earliest date available: 2021-02-26
smoothed_whesitancy_reason_not_recommended	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_whesitancy_reason_not_recommended	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_whesitancy_reason_wait_safety	Estimated percentage of respondents who say they are hesitant to get vaccinated because they want to wait to see if the COVID-19 vaccines are safe, among respondents who answered “Yes, probably”, “No, probably not”, or “No, definitely not” when asked if they would get vaccinated if offered (item V3). This series of items was shown to respondents starting in Wave 8.
#Earliest date available: 2021-02-26
smoothed_whesitancy_reason_wait_safety	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_whesitancy_reason_wait_safety	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))


#smoothed_whesitancy_reason_low_priority	Estimated percentage of respondents who say they are hesitant to get vaccinated because they want to wait to see if the COVID-19 vaccines are safe, among respondents who answered “Yes, probably”, “No, probably not”, or “No, definitely not” when asked if they would get vaccinated if offered (item V3). This series of items was shown to respondents starting in Wave 8.
#Earliest date available: 2021-02-26
smoothed_whesitancy_reason_low_priority	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_whesitancy_reason_low_priority	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))



#smoothed_whesitancy_reason_cost	Estimated percentage of respondents who say they are hesitant to get vaccinated because they want to wait to see if the COVID-19 vaccines are safe, among respondents who answered “Yes, probably”, “No, probably not”, or “No, definitely not” when asked if they would get vaccinated if offered (item V3). This series of items was shown to respondents starting in Wave 8.
#Earliest date available: 2021-02-26
smoothed_whesitancy_reason_cost	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_whesitancy_reason_cost	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))


#smoothed_whesitancy_reason_distrust_vaccines	Discontinued as of Wave 11, May 19, 2021 Estimated percentage of respondents who say they are hesitant to get vaccinated because they don’t trust COVID-19 vaccines, among respondents who answered “Yes, probably”, “No, probably not”, or “No, definitely not” when asked if they would get vaccinated if offered (item V3). This series of items was shown to respondents starting in Wave 8.
#Earliest date available: 2021-02-26
smoothed_whesitancy_reason_distrust_vaccines	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_whesitancy_reason_distrust_vaccines	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))


#smoothed_whesitancy_reason_distrust_gov	Estimated percentage of respondents who say they are hesitant to get vaccinated because they don’t trust the government, among respondents who answered “Yes, probably”, “No, probably not”, or “No, definitely not” when asked if they would get vaccinated if offered (item V3). This series of items was shown to respondents starting in Wave 8.
#Earliest date available: 2021-02-26
smoothed_whesitancy_reason_distrust_gov	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_whesitancy_reason_distrust_gov	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_whesitancy_reason_health_condition	Discontinued as of Wave 11, May 19, 2021 Estimated percentage of respondents who say they are hesitant to get vaccinated because they have a health condition that may impact the safety of a COVID-19 vaccine, among respondents who answered “Yes, probably”, “No, probably not”, or “No, definitely not” when asked if they would get vaccinated if offered (item V3). This series of items was shown to respondents starting in Wave 8.
#Earliest date available: 2021-02-26
smoothed_whesitancy_reason_health_condition	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_whesitancy_reason_health_condition	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_whesitancy_reason_pregnant	Discontinued as of Wave 11, May 19, 2021 Estimated percentage of respondents who say they are hesitant to get vaccinated because they are pregnant or breastfeeding, among respondents who answered “Yes, probably”, “No, probably not”, or “No, definitely not” when asked if they would get vaccinated if offered (item V3). This series of items was shown to respondents starting in Wave 8.
#Earliest date available: 2021-02-26
smoothed_whesitancy_reason_pregnant	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_whesitancy_reason_pregnant	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_whesitancy_reason_religious	Estimated percentage of respondents who say they are hesitant to get vaccinated because it is against their religious beliefs, among respondents who answered “Yes, probably”, “No, probably not”, or “No, definitely not” when asked if they would get vaccinated if offered (item V3). This series of items was shown to respondents starting in Wave 8.
#Earliest date available: 2021-02-26
smoothed_whesitancy_reason_religious	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_whesitancy_reason_religious	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_whesitancy_reason_other	Estimated percentage of respondents who say they are hesitant to get vaccinated for another reason, among respondents who answered “Yes, probably”, “No, probably not”, or “No, definitely not” when asked if they would get vaccinated if offered (item V3). This series of items was shown to respondents starting in Wave 8.
#Earliest date available: 2021-02-26
smoothed_whesitancy_reason_other	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_whesitancy_reason_other	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))


#smoothed_wdontneed_reason_had_covid	Estimated percentage of respondents who say they don’t need to get a COVID-19 vaccine because they already had the illness, among respondents who provided at least one reason for why they believe a COVID-19 vaccine is unnecessary.
#Earliest date available: 2021-03-12
smoothed_wdontneed_reason_had_covid	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wdontneed_reason_had_covid	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))


#smoothed_wdontneed_reason_dont_spend_time	Estimated percentage of respondents who say they don’t need to get a COVID-19 vaccine because they don’t spend time with high-risk people, among respondents who provided at least one reason for why they believe a COVID-19 vaccine is unnecessary.
#Earliest date available: 2021-03-12
smoothed_wdontneed_reason_dont_spend_time	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wdontneed_reason_dont_spend_time	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wdontneed_reason_not_high_risk	Estimated percentage of respondents who say they don’t need to get a COVID-19 vaccine because they are not in a high-risk group, among respondents who provided at least one reason for why they believe a COVID-19 vaccine is unnecessary.
#Earliest date available: 2021-03-12
smoothed_wdontneed_reason_not_high_risk	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wdontneed_reason_not_high_risk	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wdontneed_reason_precautions	Estimated percentage of respondents who say they don’t need to get a COVID-19 vaccine because they will use other precautions, such as a mask, instead, among respondents who provided at least one reason for why they believe a COVID-19 vaccine is unnecessary.
#Earliest date available: 2021-03-12
smoothed_wdontneed_reason_precautions	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wdontneed_reason_precautions	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wdontneed_reason_not_serious	Estimated percentage of respondents who say they don’t need to get a COVID-19 vaccine because they don’t believe COVID-19 is a serious illness, among respondents who provided at least one reason for why they believe a COVID-19 vaccine is unnecessary.
#Earliest date available: 2021-03-12
smoothed_wdontneed_reason_not_serious	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wdontneed_reason_not_serious	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))


#smoothed_wdontneed_reason_not_beneficial	Estimated percentage of respondents who say they don’t need to get a COVID-19 vaccine because they don’t think vaccines are beneficial, among respondents who provided at least one reason for why they believe a COVID-19 vaccine is unnecessary.
#Earliest date available: 2021-03-12
smoothed_wdontneed_reason_not_beneficial	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wdontneed_reason_not_beneficial	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wdontneed_reason_other	Estimated percentage of respondents who say they don’t need to get a COVID-19 vaccine for another reason, among respondents who provided at least one reason for why they believe a COVID-19 vaccine is unnecessary.
#Earliest date available: 2021-03-12
smoothed_wdontneed_reason_other	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wdontneed_reason_other	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))


#smoothed_wtrust_covid_info_doctors	Estimated percentage of respondents who trust doctors and other health professionals they go to for medical care to provide accurate news and information about COVID-19.
#Earliest date available: 2021-05-19
smoothed_wtrust_covid_info_doctors	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wtrust_covid_info_doctors	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wtrust_covid_info_experts	Estimated percentage of respondents who trust scientists and other health experts to provide accurate news and information about COVID-19.
#Earliest date available: 2021-05-19
smoothed_wtrust_covid_info_experts	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wtrust_covid_info_experts	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wtrust_covid_info_cdc	Estimated percentage of respondents who trust the Centers for Disease Control (CDC) to provide accurate news and information about COVID-19.
#Earliest date available: 2021-05-19
smoothed_wtrust_covid_info_cdc	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wtrust_covid_info_cdc	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wtrust_covid_info_govt_health	Estimated percentage of respondents who trust government health officials to provide accurate news and information about COVID-19.
#Earliest date available: 2021-05-19
smoothed_wtrust_covid_info_cdc	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wtrust_covid_info_cdc	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wtrust_covid_info_politicians	Estimated percentage of respondents who trust politicians to provide accurate news and information about COVID-19.
#Earliest date available: 2021-05-19
smoothed_wtrust_covid_info_politicians	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wtrust_covid_info_politicians	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wtrust_covid_info_journalists	Estimated percentage of respondents who trust journalists to provide accurate news and information about COVID-19.
#Earliest date available: 2021-05-19
smoothed_wtrust_covid_info_journalists	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wtrust_covid_info_journalists	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wtrust_covid_info_friends	Estimated percentage of respondents who trust friends and family to provide accurate news and information about COVID-19.
#Earliest date available: 2021-05-19
smoothed_wtrust_covid_info_friends	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wtrust_covid_info_friends	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wtrust_covid_info_religious	Estimated percentage of respondents who trust religious leaders to provide accurate news and information about COVID-19.
#Earliest date available: 2021-05-19
smoothed_wtrust_covid_info_religious	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wtrust_covid_info_religious	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wvaccine_likely_friends	Discontinued as of Wave 11, May 19, 2021 Estimated percentage of respondents who would be more likely to get a COVID-19 vaccine if it were recommended to them by friends and family, among respondents who have not yet been vaccinated.
#Earliest date available: 2021-01-20
smoothed_wvaccine_likely_friends	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccine_likely_friends	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wvaccine_likely_local_health	Discontinued as of Wave 8, Feb 8, 2021 Estimated percentage of respondents who would be more likely to get a COVID-19 vaccine if it were recommended to them by local health workers, among respondents who have not yet been vaccinated.
#Earliest date available: 2021-01-20
smoothed_wvaccine_likely_local_health	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccine_likely_local_health	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wvaccine_likely_who	Discontinued as of Wave 11, May 19, 2021 Estimated percentage of respondents who would be more likely to get a COVID-19 vaccine if it were recommended to them by the World Health Organization, among respondents who have not yet been vaccinated.
#Earliest date available: 2021-01-20
smoothed_wvaccine_likely_who	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccine_likely_who	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wvaccine_likely_govt_health	Discontinued as of Wave 11, May 19, 2021 Estimated percentage of respondents who would be more likely to get a COVID-19 vaccine if it were recommended to them by government health officials, among respondents who have not yet been vaccinated.
#Earliest date available: 2021-01-20
smoothed_wvaccine_likely_govt_health	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccine_likely_govt_health	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wvaccine_likely_politicians	Discontinued as of Wave 11, May 19, 2021 Estimated percentage of respondents who would be more likely to get a COVID-19 vaccine if it were recommended to them by politicians, among respondents who have not yet been vaccinated.
#Earliest date available: 2021-01-20
smoothed_wvaccine_likely_politicians	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccine_likely_politicians	"),start_day = "2020-11-01", end_day = "2021-07-01",geo_type = "county"))

#smoothed_wvaccine_likely_doctors	Discontinued as of Wave 11, May 19, 2021 Estimated percentage of respondents who would be more likely to get a COVID-19 vaccine if it were recommended to them by doctors and other health professionals they go to for medical care, among respondents who have not yet been vaccinated. This item was shown to respondents starting in Wave 8.
#Earliest date available: 2021-02-08
smoothed_wvaccine_likely_doctors	 <- suppressMessages(covidcast_signal(data_source = "fb-survey", signal = c("smoothed_wvaccine_likely_doctors	"),start_day = "2021-11-01", end_day = "2021-07-01",geo_type = "county"))


```

#### Combine Everything

```{r}

xyid_all <- lhs %>% 
            left_join(a) %>%
            left_join(g) %>%
            #left_join(d) %>%
            left_join(politics_clean %>% rename(fips=county_fips)) %>%
  
            left_join(h) %>%
            left_join(a00_clean) %>%
            left_join(distance_to_coast_df) %>%
            left_join(facilities_per_county) %>%
            left_join(google_mobility_clean) %>%
            left_join(population_differential) %>%
            left_join(masking_cleaned) %>%
            left_join(smoothed_wcovid_vaccinated_or_accept_clean %>% mutate(fips=as.numeric(fips))) %>%
            left_join(infections_clean) %>%
            dplyr::mutate(total_infected_mean_percap = total_infected_mean/population_total )  %>%
            dplyr::mutate(total_cases_percap = total_cases/population_total )  %>%
            left_join(bea_wide) %>%
            dplyr::mutate_at(vars(starts_with("gdp")), ~ ./population_total) %>%
            left_join(bea_wide_share) %>%
            left_join(safegraph) %>%
            mutate(safegraph_pop_flows_self_total_percap = safegraph_pop_flows_self_total/population_total )  %>%
            mutate(safegraph_pop_flows_external_total_percap = safegraph_pop_flows_external_total/population_total )  %>%
            mutate(safegraph_pop_flows_fromexternal_total_percap = safegraph_pop_flows_fromexternal_total/population_total )  %>%

            dplyr::filter(!is.na(fips)) %>%
            dplyr::mutate(fips_state= floor( fips/1000 )*1000) %>%
            left_join(state_previous_child_vaccinated_perc) %>%

            dplyr::mutate(trump_swing2020 = donaldjtrump_2020-donaldtrump_2016) %>%
            dplyr::mutate(trump_swing2016 = donaldtrump_2016-mittromney_2012) %>%
  
            dplyr::mutate(fips_state=floor(fips/1000)*1000) %>%
            left_join(  states_sf_tigris_continental %>% as.data.frame() %>% clean_names() %>% mutate(fips_state=as.numeric(statefp)*1000) %>% dplyr::select(fips_state,fold)  ) %>% 
            dplyr::mutate_if(is.character, ~gsub('[^ -~]', '', .)) %>%
            dplyr::mutate(covid_deaths_percap = deaths/population_total ) %>%
            dplyr::mutate(vaccine_facilities_percap = vaccine_facilities_count/population_total ) %>%
            dplyr::filter(recip_state!=c("PR","GU" )) %>% #Dropping PR and Guam
            dplyr::filter(fips!=2270) %>% #drop one broken fips code
            dplyr::filter(!is.na(fold)) %>% 
            dplyr::mutate_if(is.numeric, ~replace(., is.infinite(.), NA)) 
dim(xyid_all) #3282   34
table(xyid_all$fold, useNA="always") #67 we're dropping 67 counties that aren't continental 


```

### Summary Statistics

```{r, results='asis'}


xyid_all %>% as.data.frame()  %>% #There's some rough strings in county names
  summarytools::dfSummary( plain.ascii = FALSE,  graph.magnif = 0.75, valid.col = FALSE, #
                                          #tmp.img.dir = "/mnt/8tb_a/rwd_github_private/cleancovidcounts/docs/temp/",
                                          style = 'multiline',
                                          max.distinct.values=10) %>% print( method = 'render')

```

### Raw Data

Here are the full raw values for the full dataset.

```{r, results='asis'}

p_load(DT); #install.packages('DT')
DT::datatable(xyid_all, rownames = FALSE)

```

# Step 4: Propose Features and a Credible Measurement Strategy

We divide features into groups: demography, politics, medical,
education, and wealth. We then fit models over unique subsets of groups
of features, 31 in total.

Multiple proxies for the same concept. Multiple measures of the same.
Colinear.

```{r}

var_sets <- list(
  
  'economy'=c("gdp_all_industry_total" ,
              "gdp_private_industries"  ,                                                    
               "gdp_agriculture_forestry_fishing_and_hunting",
               "gdp_mining_quarrying_and_oil_and_gas_extraction","gdp_utilities"  ,                                                             
               "gdp_construction",
               "gdp_manufacturing",
               "gdp_durable_goods_manufacturing",
              "gdp_nondurable_goods_manufacturing",
              "gdp_wholesale_trade","gdp_retail_trade" ,                                                           
               "gdp_transportation_and_warehousing",
              "gdp_information",
              "gdp_finance_insurance_real_estate_rental_and_leasing",                        
              "gdp_finance_and_insurance",
              "gdp_real_estate_and_rental_and_leasing",
              "gdp_professional_and_business_services" ,                                     
               "gdp_professional_scientific_and_technical_services",
              "gdp_management_of_companies_and_enterprises",
              "gdp_administrative_and_support_and_waste_management_and_remediation_services",
               "gdp_educational_services_health_care_and_social_assistance",
              "gdp_educational_services",
              "gdp_health_care_and_social_assistance",                                       
               "gdp_arts_entertainment_recreation_accommodation_and_food_services",
              "gdp_arts_entertainment_and_recreation",
              "gdp_accommodation_and_food_services"  ,                                       
               "gdp_other_services_except_government_and_government_enterprises",
              "gdp_government_and_government_enterprises",
              "gdp_natural_resources_and_mining"    ,                                        
              "gdp_trade","gdp_transportation_and_utilities",
              "gdp_manufacturing_and_information" ,                                          
               "gdp_private_goods_producing_industries_2",
              "gdp_private_services_providing_industries_3" #,

              #"gdp_private_industries_perc","gdp_agriculture_forestry_fishing_and_hunting_perc"    ,                            
              # "gdp_mining_quarrying_and_oil_and_gas_extraction_perc","gdp_utilities_perc","gdp_construction_perc"  ,                                                          
              # "gdp_manufacturing_perc","gdp_durable_goods_manufacturing_perc","gdp_nondurable_goods_manufacturing_perc" ,                                         
              # "gdp_wholesale_trade_perc","gdp_retail_trade_perc","gdp_transportation_and_warehousing_perc"      ,                                    
              #"gdp_information_perc","gdp_finance_insurance_real_estate_rental_and_leasing_perc","gdp_finance_and_insurance_perc"   ,                                                
              # "gdp_real_estate_and_rental_and_leasing_perc","gdp_professional_and_business_services_perc","gdp_professional_scientific_and_technical_services_perc"  ,                        
              # "gdp_management_of_companies_and_enterprises_perc","gdp_administrative_and_support_and_waste_management_and_remediation_services_perc" ,"gdp_educational_services_health_care_and_social_assistance_perc" ,                 
              # "gdp_educational_services_perc","gdp_health_care_and_social_assistance_perc","gdp_arts_entertainment_recreation_accommodation_and_food_services_perc" ,          
              #"gdp_arts_entertainment_and_recreation_perc","gdp_accommodation_and_food_services_perc","gdp_other_services_except_government_and_government_enterprises_perc" ,            
              # "gdp_government_and_government_enterprises_perc","gdp_natural_resources_and_mining_perc","gdp_trade_perc" ,                                                                  
              #"gdp_transportation_and_utilities_perc","gdp_manufacturing_and_information_perc","gdp_private_goods_producing_industries_2_perc" , "gdp_private_services_providing_industries_3_perc"           
),
  
  'masking'=c('masking_never',
              'masking_rarely',
              'masking_sometimes',
              'masking_frequently',
              'masking_always'),
  
  'urbanicity'= c('population_total',
                  'rucc_2013',
                  "density_per_square_mile_of_land_area_population",
                  'population_differential'),
  
  'race'= c('white_perc',
            "black_perc",
            "asian_perc",
            'hispanic_perc',
            'native_perc'),
  
  'age'=c("total_age0to17_perc",
          "total_age18to64_perc",
          "total_age65plus_perc",
          "total_age85plusr_perc"),
  
  'politics'= c('trump_swing2016',
                'trump_swing2020',
                'georgewbush_2000',
                'georgewbush_2004',
                'johnmccain_2008',
                'mittromney_2012',
                'donaldtrump_2016',
                'donaldjtrump_2020'
                ),
  
  'vaccinations'=c('flu_vaccinations_perc_medicare2018',
                   'previous_child_vaccinated_perc',
                   'smoothed_wcovid_vaccinated_or_accept'),
  
  'medicalresources' = c('active_physicians_per_100000_population_2018_aamc',
                         'total_hospitals_2019',
                         'dentists_percap_2019',
                         'mental_health_providers_percap_2020',
                         'primary_care_physicians_percap_2018',
                         'uninsured_perc_sahi2018',
                         'vaccine_facilities_percap',
                         'vaccine_facilities_count'
                         ),
  
  'covid'= c('covid_deaths_percap',
             'deaths',
             'total_cases',
             'total_infected_mean',
             'ratio_estimated_cases_to_measured',
             'total_cases_percap',
             'total_infected_mean_percap'
             ), 
  
  'healthconditions'=c(
                       'adult_obesity_perc_dss2017',
                      'adult_smoking_perc_brfss2018',
                      'low_birthweight_perc_nchs2019',
                      'poor_or_fair_health_perc_brfss2018',
                      'preventable_hospital_stays_percap2018',
                      'mammography_screening_percap2018'
                      ),
  
  'education' = c(
                  "percent_of_adults_with_less_than_a_high_school_diploma_2014_18",
                  "percent_of_adults_with_a_bachelors_degree_or_higher_2014_18",
                  "percent_of_adults_completing_some_college_or_associates_degree_2014_18",
                  "percent_of_adults_with_a_high_school_diploma_only_2014_18"),
  
  'wealth' = c(
               "unemployment_rate_2018",
               "median_household_income_2018"
               ),
  
  'geography'=c(
                'distance_to_coast_km',
                "area_in_square_miles_land_area"
                ),
  
  'mobilitychange'=c(
               #Google
               'retail_and_recreation_percent_change_from_baseline',
               'grocery_and_pharmacy_percent_change_from_baseline',
               'parks_percent_change_from_baseline',
               'transit_stations_percent_change_from_baseline',
               'workplaces_percent_change_from_baseline',
               'residential_percent_change_from_baseline'),
   'mobilityamount' = c(
                #Safegraph
              'safegraph_pop_flows_self_total',
              'safegraph_pop_flows_external_total',
              'safegraph_pop_flows_fromexternal_total',
              'safegraph_pop_flows_self_total_percap',
              'safegraph_pop_flows_external_total_percap',
              'safegraph_pop_flows_fromexternal_total_percap'
              )
)

unlist(var_sets) %>% length() #currently 42 features






```

# Step 5: Propose a Functional Search Space (Inductive Priors)

```{r}

#We pass this function a set of variables and it creates all the train test splits

#q=c("economy","masking","urbanicity","race","age","politics","vaccinations","medicalresources", "covid","healthconditions", "education","wealth","geography","mobilitychange","mobilityamount")
#vars_to_include <- var_sets[q] %>% unlist()
#print(model_name)


#Library Loads
#We build all the test and validation folds above
#We can pass to this function a set of variables and it'll fit the models on each fold for us
p_load(glmnet); #install.packages('glmnet')
p_load(xgboost)
#Distill the xgboost model into a lasso
#devtools::install_github("ModelOriented/modelStudio")
p_load("DALEX")
p_load(DALEXtra)
p_load("modelStudio")
p_load("rSAFE")
p_load(Metrics)
p_load(rjson) 
p_load(miceRanger)

#Xgboost with imputation
pars_best <- list( 
  booster = "gbtree"
  , eta = 0.01 #getBestPars(optObj)$eta #they picked a very low learning rate #lower learning rate for the final one
  , max_depth = 5 #grid_result_best$max_depth
  #, min_child_weight = 15 #grid_result_best$min_child_weight
  , subsample = 0.775 #grid_result_best$subsample
  , colsample_bynode = 0.148
  , objective = "reg:squarederror"
  , eval_metric = "rmse"
)
    

p_load(doMC)
registerDoMC(cores = 64)
try({detach("package:tidylog", unload=TRUE)})
#Function to handle everything by fold
fit_model <- function(model_name='',vars_to_include=c('')){

    yid_all <- xyid_all %>% dplyr::select(fold, fips,fips_state, y=uptake_max)  #This subsets it to just our dv , plus Ids
    xid_all <- xyid_all %>% dplyr::select(-uptake_max)  #this to just the vars we want to include, plus IDs
    
    for(test_fold in 1:6){

      path_predictions <- glue::glue("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/test_predictions/{model_name}{test_fold}.parquet")
      print(path_predictions)
      if(file.exists(path_predictions)){print("File exists skipping"); next}
      vars_to_include_collapsed <- paste(vars_to_include, collapse=";")
      
      id_train1 <- yid_all %>% dplyr::filter(!fold %in% c(test_fold)) %>% dplyr::select(fold, fips,fips_state,y) %>% mutate(model_name=model_name, vars_to_include=vars_to_include_collapsed)
      id_test1 <- yid_all %>% dplyr::filter(fold %in% c(test_fold)) %>% dplyr::select(fold, fips,fips_state,y) %>% mutate(model_name=model_name, vars_to_include=vars_to_include_collapsed)
      
      x_train1 <- xid_all %>% dplyr::filter(!fold %in% c(test_fold)) %>% dplyr::select(one_of(vars_to_include)) 
      x_test1 <- xid_all %>% dplyr::filter(fold %in% c(test_fold))  %>% dplyr::select(one_of(vars_to_include))
      y_train1 <- yid_all %>% dplyr::filter(!fold %in% c(test_fold)) %>% dplyr::select(y) #this subsets it to everything but the test fold
      y_test1 <- yid_all %>% dplyr::filter(fold %in% c(test_fold)) %>% dplyr::select(y) 
      
      remaining_folds1 <- id_train1$fold %>% unique()
      Folds1 <- list(
          Fold1 = which(id_train1$fold==remaining_folds1[1]) #There are 5 folds left to choose from, here we fit on everything but the first one
        , Fold2 = which(id_train1$fold==remaining_folds1[2]) #Everything but the second one
        , Fold3 = which(id_train1$fold==remaining_folds1[3])
        , Fold4 = which(id_train1$fold==remaining_folds1[4])
        , Fold5 = which(id_train1$fold==remaining_folds1[5])
      )
      
      #To do this correctly, we have to do each validation fold separately
      #So first a train/test split, fit on the train impute on the test
      #But then also 5 more validation datasets. Maybe we just say that CV is optimistic and the test performance is going to be worse
      print("Imputing Missing Values")
      x_imputed_train1 <- x_train1 #mice errors out if there are no missing
      x_imputed_test1 <- x_test1
      miceObj1 <- NULL
      tictoc::tic()
        tryCatch(
          expr ={
            #There's a bug if it only has 2 dim 'x' must be an array of at least two dimensions
            miceObj1 <- miceRanger(data=x_train1 %>% dplyr::select(one_of(vars_to_include))  %>% mutate(ones=1) %>% as.data.table()  , m=1    , returnModels = TRUE    , verbose=F  )
            x_imputed_train1 <- completeData(miceObj1)$Dataset_1 %>% dplyr::select(-ones)  #%>% Rfast::data.frame.to_matrix(col.names=T)
            x_imputed_test1 <- impute(x_test1 %>% dplyr::select(one_of(vars_to_include)) %>% mutate(ones=1)  %>% as.data.table(), miceObj1, verbose=F)$imputedData[[1]] %>% dplyr::select(-ones) 
          },
          error= function(e){
              print("Errored out, impute only on test")
              try({
                miceObj1 <- miceRanger(data=x_test1 %>% dplyr::select(one_of(vars_to_include)) %>% mutate(ones=1) %>% as.data.table()  , m=1    , returnModels = TRUE    , verbose=F  ) #in the rare case you only end up with missing in the test then only impute in the test
                x_imputed_test1 <<- completeData(miceObj1)$Dataset_1  %>% dplyr::select(-ones)  #%>% Rfast::data.frame.to_matrix(col.names=T)
              })
          }
        )
      tictoc::toc()

      x_imputed_interactions_train1 <- model.matrix( ~.^2, data=x_imputed_train1 ) %>% as.data.frame() %>% janitor::clean_names()  %>% cbind(x_imputed_train1) %>% Rfast::data.frame.to_matrix(col.names=T) 
      x_imputed_interactions_test1 <- model.matrix( ~.^2, data=x_imputed_test1 ) %>% as.data.frame() %>% janitor::clean_names()  %>% cbind(x_imputed_test1) %>% Rfast::data.frame.to_matrix(col.names=T) 
      #dim(x_imputed_interactions_train1)

      #Lasso ############################################
      print("Lasso")
      tictoc::tic()
        lasso_1 = cv.glmnet(x=x_imputed_interactions_train1 %>% Rfast::data.frame.to_matrix(col.names=T), y=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T) ,  foldid = id_train1$fold %>% droplevels() %>% as.integer())
        lasso_1_coefs_min <- coef(lasso_1, s = "lambda.min") %>% as.matrix() %>% as.data.frame() %>%  filter(s1!=0)  %>% arrange(s1)
        id_test1$y_hat_lasso_imputed <- predict(lasso_1, newx=x_imputed_interactions_test1 %>% Rfast::data.frame.to_matrix(col.names=T), s = c("lambda.1se"), gamma="lambda.1se")[,1] #Test predictions 
        id_test1$coefs_lasso <- lasso_1_coefs_min %>% unlist() %>% setNames(rownames(lasso_1_coefs_min)) %>% toJSON(indent=0, method="C" )
      tictoc::toc()
      
      #xgboost no interact ###############################
      print("xgboost")
      tictoc::tic()
        xgboost1_imputed <- xgb.cv(params = pars_best, data = xgb.DMatrix( x_imputed_interactions_train1 %>% Rfast::data.frame.to_matrix(col.names=T), label=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T)) , nround = 3000, 
                           folds = Folds1, prediction = F, showsd = F, early_stopping_rounds = 10, maximize = F, verbose = 0,nthread=64) #mf set threads to cores not threads
        
        xgboost1_nocv_imputed  <-  xgb.train(params=pars_best, data= xgb.DMatrix( x_imputed_interactions_train1 %>% Rfast::data.frame.to_matrix(col.names=T),label=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T)) ,
                                     nrounds=xgboost1_imputed$best_iteration, verbose = 0, nthread=64) #mf set threads to cores not threads
        id_test1$y_hat_xgboost_imputed <- predict(xgboost1_nocv_imputed, xgb.DMatrix( x_imputed_interactions_test1 %>% Rfast::data.frame.to_matrix(col.names=T), 
                                                                                      label=y_test1 %>% Rfast::data.frame.to_matrix(col.names=T )) )
      tictoc::toc()
      #Distil xgboost ###############################    
      # print("Distil xgboost into a lasso")
      # tictoc::tic()
      #   explainer_xgboost1_nocv_imputed <- DALEX::explain(xgboost1_nocv_imputed,
      #                          data = x_imputed_interactions_train1 %>% Rfast::data.frame.to_matrix(col.names=T),
      #                          y =y_train1 %>% Rfast::data.frame.to_matrix(col.names=T),
      #                          label = "xgboost")
      # 
      #   #This is the speed bottleneck, interactions is very slow
      #   safe_extractor_xgboost1_nocv_imputed <- safe_extraction(explainer_xgboost1_nocv_imputed, penalty = "MBIC", verbose = T, interactions=F) #, inter_param=0.05,inter_threshold=0.05 I was wrong and this is not faster if you precompute interactions
      #   x_imputed_interactions_train1_transformed_xgboost1 <- safely_transform_data(safe_extractor_xgboost1_nocv_imputed, x_imputed_interactions_train1 %>% Rfast::data.frame.to_matrix(col.names=T), verbose = F)
      #   x_imputed_interactions_test1_transformed_xgboost1 <- safely_transform_data(safe_extractor_xgboost1_nocv_imputed, x_imputed_interactions_train1 %>% Rfast::data.frame.to_matrix(col.names=T), verbose = F)
      # 
      #   lasso_1_transformed_xgboost1 = cv.glmnet(x=x_imputed_interactions_train1_transformed_xgboost1 %>% Rfast::data.frame.to_matrix(col.names=T), y=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T) , 
      #                                            foldid = id_train1$fold %>% droplevels() %>% as.integer())
      #   lasso_1_transformed_coefs_min <- coef(lasso_1_transformed_xgboost1, s = "lambda.min") %>% as.matrix() %>% as.data.frame() %>%  filter(s1!=0)  %>% arrange(s1) 
      #   id_test1$coefs_lasso_transformed <- lasso_1_transformed_coefs_min %>% unlist() %>% setNames(rownames(lasso_1_transformed_coefs_min)) %>% toJSON(indent=0, method="C" )
      # 
      #   id_test1$y_hat_lasso_imputed_transformed_min  <- predict(lasso_1_transformed_xgboost1, newx=x_imputed_interactions_test1_transformed_xgboost1 %>% Rfast::data.frame.to_matrix(col.names=T),
      #                                                            s = c("lambda.min"), gamma="lambda.min")[,1] #Test predictions 
      # tictoc::toc()
      arrow::write_parquet(id_test1, path_predictions)  
      #lapply(id_test1 %>% dplyr::select(starts_with("y_hat")), FUN=function(x) { Metrics::rmse(id_test1$y,x) }) %>% as.data.frame() %>% sort() #
    }
}



#p_load(ingredients)
#p_load(iBreakDown)
#p_load(auditor)

#explainer_lasso_1_transformed_xgboost1_nocv <- explain(lasso_1_transformed_xgboost1_nocv,
#                                                         data = x_imputed_train1_transformed_xgboost1  %>% Rfast::data.frame.to_matrix(col.names=T),
#                                                         y =y_train1 %>% Rfast::data.frame.to_matrix(col.names=T),
#                                                         label = "lasso_1_transformed_xgboost1_nocv")
##modelStudio(explainer_lasso_1_transformed_xgboost1_nocv) #somehow still slow
      

```

# Fit Models

```{r}

all_sets <- names(var_sets)
t_all <-c( 
 combn(all_sets, m=15) %>% apply(2, list, simplify = T) %>% unlist(recursive=F) , #just 1, all of them
 #combn(all_sets, m=14) %>% apply(2, list, simplify = T) %>% unlist(recursive=F) , #just 1, all of them
 #combn(all_sets, m=13) %>% apply(2, list, simplify = T) %>% unlist(recursive=F) , #just 1, all of them
 #combn(all_sets, m=12) %>% apply(2, list, simplify = T) %>% unlist(recursive=F) , #13, each excluding 1
 #combn(all_sets, m=11) %>% apply(2, list, simplify = T) %>% unlist(recursive=F) ,
 #combn(all_sets, m=10) %>% apply(2, list, simplify = T) %>% unlist(recursive=F) ,
 #combn(all_sets, m=9) %>% apply(2, list, simplify = T) %>% unlist(recursive=F) ,
 #combn(all_sets, m=8) %>% apply(2, list, simplify = T) %>% unlist(recursive=F) ,
 #combn(all_sets, m=7) %>% apply(2, list, simplify = T) %>% unlist(recursive=F) ,
 #combn(all_sets, m=6) %>% apply(2, list, simplify = T) %>% unlist(recursive=F) ,
 #combn(all_sets, m=5) %>% apply(2, list, simplify = T) %>% unlist(recursive=F) ,
 #combn(all_sets, m=4) %>% apply(2, list, simplify = T) %>% unlist(recursive=F),
 #combn(all_sets, m=3) %>% apply(2, list, simplify = T) %>% unlist(recursive=F),
 combn(all_sets, m=2) %>% apply(2, list, simplify = T) %>% unlist(recursive=F), #78 pairs of variables
 combn(all_sets, m=1) %>% apply(2, list, simplify = T) %>% unlist(recursive=F) #12 combos
)
length(t_all) #it's now up to 16,383 models
#Ok now you can just iterate through this list, create a name for the run, list the vars, and then pass it
#It's  119 models
model_results_list=list()


t_all_small <- list( 
  c("economy","masking","urbanicity","race","age","politics","vaccinations","medicalresources", "covid","healthconditions", "education","wealth","geography","mobilitychange","mobilityamount"),  
  c("economy","masking","urbanicity","race","age","vaccinations","medicalresources", "covid","healthconditions", "education","wealth","geography","mobilitychange","mobilityamount")
  )
q=t_all_small[[1]]
model_name <- sort(paste0(q, collapse="_"))
vars_to_include <- var_sets[q] %>% unlist()
tictoc::tic()
for(q in t_all){
  model_name <- sort(paste0(q, collapse="_"))
  vars_to_include <- var_sets[q] %>% unlist()
  print(model_name)
  #fit_model(model_name=model_name, vars_to_include=vars_to_include) #fit it first without
  fit_model(model_name=model_name, vars_to_include=vars_to_include)
  

}
tictoc::toc()


```

#### Test Performance

Ok this is good. We can see that the null model is off by about 9% on
average.

```{r}

test_predictions <- arrow::open_dataset("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/test_predictions/")  %>% dplyr::collect()  %>% mutate(fold=as.numeric(fold))

#Compile results

#There's also this function here
#https://rdrr.io/cran/MBESS/man/ci.rmsea.html
#ci.rmsea(rmsea, df, N, conf.level = 0.95, alpha.lower = NULL, alpha.upper = NULL)

#https://gist.github.com/brshallo/7eed49c743ac165ced2294a70e73e65e
#' @param rmse Root mean squared error on your sample
#' @param df Degrees of Freedom in your model. In this case it should be the
#'   same as the number of observations in your sample.
rmse_interval <- function(rmse, deg_free, p_lower = 0.05, p_upper = 0.95){
  tibble(.pred_lower = sqrt(deg_free / qchisq(p_upper, df = deg_free)) * rmse,
         .pred_upper = sqrt(deg_free / qchisq(p_lower, df = deg_free)) * rmse)
}

nullmodel <-   test_predictions %>% dplyr::select(fold, fips, y) %>% distinct() %>% left_join(
  bind_rows(  
      test_predictions %>% filter(fold!=1) %>% dplyr::select(y) %>% summarise(y_hat=mean(y))  %>% mutate(fold=1),
      test_predictions %>% filter(fold!=2) %>% dplyr::select(y) %>% summarise(y_hat=mean(y))  %>% mutate(fold=2),
      test_predictions %>% filter(fold!=3) %>% dplyr::select(y) %>% summarise(y_hat=mean(y))  %>% mutate(fold=3),
      test_predictions %>% filter(fold!=4) %>% dplyr::select(y) %>% summarise(y_hat=mean(y))  %>% mutate(fold=4),
      test_predictions %>% filter(fold!=5) %>% dplyr::select(y) %>% summarise(y_hat=mean(y))  %>% mutate(fold=5),
      test_predictions %>% filter(fold!=6) %>% dplyr::select(y) %>% summarise(y_hat=mean(y))  %>% mutate(fold=6)
  )
) %>% mutate(model_name="null_model_intercept_outofsample") %>% mutate(y_hat_lasso_imputed=y_hat)  %>% mutate(y_hat_xgboost_imputed=y_hat)
  

performance <- bind_rows(test_predictions,
                 nullmodel)  %>%
                 #mutate(residual=y_hat-uptake_max) %>%
                 group_by(model_name) %>%
                 summarise(n=n(), 
                           #rmse_lasso_imputed_transformed=Metrics::rmse(y,y_hat_lasso_imputed_transformed_min),
                           rmse_xgboost_imputed=Metrics::rmse(y,y_hat_xgboost_imputed),
                           rmse_lasso_imputed=Metrics::rmse(y,y_hat_lasso_imputed),
                           #mae_lasso_imputed_transformed=Metrics::mae(y,y_hat_lasso_imputed_transformed_min),
                           mae_xgboost_imputed=Metrics::mae(y,y_hat_xgboost_imputed),
                           mae_lasso_imputed=Metrics::mae(y,y_hat_lasso_imputed)
                           ) 

  
  
```

# Step 7: Interpret Models

# Results

Here we show the out of sample performance of each model in terms of
mean absolute error and then by root mean squared error (with 95%
confidence bounds). The best performing model can reconstruct the true
vaccination rate to within less than 1%, while the worst is within 8%.
The top three performing models are 0.8%, 1.7%, and 2.2% within the true
vaccination rate. The top model is a nearly kitchen sink model,
including demographics, education, wealth, and politics, but excluding
medical variables. The second best excludes wealth, the third best
excludes politics. The same three models are the best performing in
terms of RMSE, except the order changes with
demography_politics_education coming in first, followed by
demography_education, and then demography_politics_education_wealth.

The value added then of political measures over just demographic and
education measures in practice is about half a percent. Too small to
matter substantively in terms of policy and planning. In combination
with wealth, its value added is about 1.4% which might matter, but again
would not substantively change one's perception's of a county being a
high, middling, or low vaccination uptake population. Demographics and
education alone are sufficient to correctly guess the vaccine status of
counties. Beyond that we see evidence of either over fitting or
underfitting, with additional measures making out of sample predictions
worse on average.

```{r}
p_performance_mae <- 
            performance %>% 
              dplyr::select(model_name, starts_with("mae")) %>%
              mutate(model_name=fct_reorder(model_name %>% str_replace_all("_"," ") %>% stringr::str_wrap(width = 100) %>% as.factor() , mae_xgboost_imputed, .desc = T) ) %>%
              pivot_longer(-model_name) %>% 
              ggplot( aes(x = model_name, y = value, col=name)) + 
              #geom_pointrange(aes(ymax = residual_rmse_05, ymin = residual_rmse_95), color = "darkblue") +
              geom_point(aes(x = model_name, y = value)) + #, col="red" 
              #geom_text(aes(label = model_name), nudge_x = 0.15) + 
              scale_x_discrete("") + 
              #geom_hline(yintercept = 0, color = "red") + 
              theme_bw() + 
              theme(text = element_text(size=10)) +
              ylab(NULL) + 
              coord_flip() +
              ggtitle("Out of Sample MAE by Group of Variables Included") + scale_y_continuous(n.breaks = 20)

```

```{r}
p_performance
ggsave(filename="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/docs/plots/p_performance_mae.pdf", plot=p_performance_mae, width=20, height=nrow(performance)/2, limitsize=F) 
```

```{r, results='asis'}

p_load(DT); #install.packages('DT')
DT::datatable(performance %>% arrange(rmse_validation ) %>% mutate_if(is.numeric, round,3), rownames = FALSE)

```

```{r}
p_performance_mae_perc <- 
            performance %>% 
              dplyr::select(model_name, starts_with("mae")) %>%
              mutate(model_name=fct_reorder(model_name %>% str_replace_all("_"," ") %>% stringr::str_wrap(width = 100) %>% as.factor() , mae_xgboost_imputed, .desc = T) ) %>%
              pivot_longer(-model_name) %>% 
              mutate(value=value/0.08945315) %>%
              ggplot( aes(x = model_name, y = value, col=name)) + 
              #geom_pointrange(aes(ymax = residual_rmse_05, ymin = residual_rmse_95), color = "darkblue") +
              geom_point(aes(x = model_name, y = value)) + #, col="red" 
              #geom_text(aes(label = model_name), nudge_x = 0.15) + 
              scale_x_discrete("") + 
              #geom_hline(yintercept = 0, color = "red") + 
              theme_bw() + 
              theme(text = element_text(size=10)) +
              ylab(NULL) + 
              coord_flip() +
              ggtitle("Out of Sample MAE by Group of Variables Included") + scale_y_continuous(n.breaks = 20) + ylab("Percent Out of Sample Error Relative to Null Model")

```

```{r}
p_performance_mae_perc
ggsave(filename="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/docs/plots/p_performance_mae_perc.pdf", plot=p_performance_mae_perc, width=20, height=nrow(performance)/2, limitsize=F) 
```

```{r}
p_load(scales)
p_performance_rmse <- 
            performance %>% 
              dplyr::select(model_name, starts_with("rmse")) %>%
              mutate(model_name=fct_reorder(model_name %>% str_replace_all("_"," ") %>% stringr::str_wrap(width = 100) %>% as.factor() , rmse_xgboost_imputed, .desc = T) ) %>%
              pivot_longer(-model_name) %>% 
              ggplot( aes(x = model_name, y = value, col=name)) + 
              #geom_pointrange(aes(ymax = residual_rmse_05, ymin = residual_rmse_95), color = "darkblue") +
              geom_point(aes(x = model_name, y = value)) + #, col="red" 
              #geom_text(aes(label = model_name), nudge_x = 0.15) + 
              scale_x_discrete("") + 
              #geom_hline(yintercept = 0, color = "red") + 
              theme_bw() + 
              theme(text = element_text(size=10)) +
              ylab(NULL) + 
              coord_flip() +
              ggtitle("Out of Sample RMSE by Group of Variables Included") + scale_y_continuous(n.breaks = 20)
```

```{r}
p_performance_rmse 
ggsave(filename="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/docs/plots/p_performance_rmse.pdf", plot=p_performance_rmse, width=20, height=nrow(performance)/2, limitsize=F) 

```

```{r, results='asis'}

p_load(DT); #install.packages('DT')
DT::datatable(performance %>% arrange(mae_xgboost_imputed ) %>% mutate_if(is.numeric, round,3), rownames = FALSE)

```

```{r}
p_load(scales)
p_performance_rmse_perc <- 
            performance %>% 
              dplyr::select(model_name, starts_with("rmse")) %>%
              mutate(model_name=fct_reorder(model_name %>% str_replace_all("_"," ") %>% stringr::str_wrap(width = 100) %>% as.factor() , rmse_xgboost_imputed, .desc = T) ) %>%
              pivot_longer(-model_name) %>% 
              mutate(value=value/0.11024343) %>%
              ggplot( aes(x = model_name, y = value, col=name)) + 
              #geom_pointrange(aes(ymax = residual_rmse_05, ymin = residual_rmse_95), color = "darkblue") +
              geom_point(aes(x = model_name, y = value)) + #, col="red" 
              #geom_text(aes(label = model_name), nudge_x = 0.15) + 
              scale_x_discrete("") + 
              #geom_hline(yintercept = 0, color = "red") + 
              theme_bw() + 
              theme(text = element_text(size=10)) +
              ylab(NULL) + 
              coord_flip() +
              ggtitle("Out of Sample RMSE by Group of Variables Included") + scale_y_continuous(n.breaks = 20) + ylab("Percent Out of Sample RMSE Relative to Null Model")
```

```{r}
p_performance_rmse_perc 
ggsave(filename="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/docs/plots/p_performance_rmse_perc.pdf", plot=p_performance_rmse_perc, width=20, height=nrow(performance)/2, limitsize=F) 

```

Out of sample performance by county

```{r}

#test_predictions$model_name %>% unique()

model_1 <- test_predictions %>% 
  dplyr::filter(model_name=='economy_masking_urbanicity_race_age_politics_vaccinations_medicalresources_covid_healthconditions_education_wealth_geography_mobilitychange_mobilityamount')
model_2  <- test_predictions %>% 
  dplyr::filter(model_name=='economy_masking_urbanicity_race_age_vaccinations_medicalresources_covid_healthconditions_education_wealth_geography_mobilitychange_mobilityamount')

compare_with_and_without_politics <- 
  model_1 %>% mutate(residual=y_hat_xgboost_imputed-y) %>% dplyr::select(fips, fips_state, y, y_hat_1=y_hat_xgboost_imputed, residual_1=residual) %>%
  left_join( 
  model_2 %>% mutate(residual=y_hat_xgboost_imputed-y)  %>% dplyr::select(fips, fips_state, y, y_hat_2=y_hat_xgboost_imputed, residual_2=residual) ) %>%
  mutate(change_in_absolute_error=abs(residual_1)-abs(residual_2))

summary(compare_with_and_without_politics$residual_1 %>% abs()) #
summary(compare_with_and_without_politics$residual_2 %>% abs()) #
summary(compare_with_and_without_politics$change_in_absolute_error) #So the absolute error tends to go up 0.8% on average

```

```{r}
compare_with_and_without_politics %>% ggplot(aes(change_in_absolute_error)) + geom_histogram() + ggtitle("Change in Absolute Error from Adding Politics")
```

Removing politics makes predictions slightly worse along the
predominantly Hispanic counties along the Texas border with Mexico, as
well as Nevada.

```{r}

#devtools::install_github("UrbanInstitute/urbnmapr")
library(tidyverse)
library(urbnmapr)

states_sf <- get_urbn_map("states", sf = TRUE)
counties_sf <- get_urbn_map("counties", sf = TRUE) %>% mutate(fips=county_fips %>% as.numeric())
map_data <- left_join(counties_sf, compare_with_and_without_politics) 

p <-   ggplot() +
       geom_sf(data=map_data, aes(fill=change_in_absolute_error) ,  color = NA) +
       geom_sf(data=states_sf, fill=NA ,  color = "black") +
    #xlim(c(-170,-55)) + ylim(c(20,70)) +
  #geom_polygon(color = NA) +
  #coord_map(projection = "albers", lat0 = 39, lat1 = 45) +
  labs(fill = "Change in Absolute Error\nfrom Including Politics\n(Red is Worse)")  +
  scale_fill_gradient2(trans="reverse") # 

```

```{r}
p
```

### The role of variables in the politics model

In order, the model attributes variation to trump support, college
education, income, age 65 or older and percent black. In short, the most
vaccinated county is likely to be a Democratic, college educated, rich,
old, and white.

```{r, eval=T, echo=F}

p_load(SHAPforxgboost)
model_folds <- test_predictions %>% dplyr::select(fold, model_name, path_model,vars_to_include,vars_to_include_pruned) %>% distinct()

this_model_name <- "economy_masking_urbanicity_race_age_politics_vaccinations_medicalresources_covid_healthconditions_education_wealth_geography_mobilitychange_mobilityamount"
#this_model_name <- "urbanicity_race_age_vaccinations_medicalresources_covid_healthconditions_education_wealth_geography_mobility"

#Fold 1
this_run <- model_folds %>% dplyr::filter(fold==1, model_name==this_model_name) 
x_train <- xyid_all %>% dplyr::filter(fold %in% this_run$fold)  %>% dplyr::select(one_of(this_run$vars_to_include_pruned %>% str_split(pattern=";", simplify =T) %>% as.vector())) #
fips <- xyid_all %>% dplyr::filter(fold %in% this_run$fold) %>% pull(fips)
xgboost_for_shap <- xgb.load(this_run$path_model)
shap_values <- SHAPforxgboost::shap.values(xgb_model = xgboost_for_shap , x_train =  x_train  %>% Rfast::data.frame.to_matrix(col.names=T ) )
shap_long1 <- shap.prep(xgb_model = xgboost_for_shap, x_train = x_train  %>% Rfast::data.frame.to_matrix(col.names=T )   ) #it needs column names
shap_long1$fips <- fips[shap_long1$ID]
shap_long1$fold <- 1
shap_int1 <- shap.prep.interaction(xgb_mod = xgboost_for_shap, x_train = x_train  %>% Rfast::data.frame.to_matrix(col.names=T )) #This one is trickier because it's an array

dim(shap_int1) #tests obs by features by features

#Fold 2
this_run <- model_folds %>% dplyr::filter(fold==2, model_name==this_model_name) 
x_train <- xyid_all %>% dplyr::filter(fold %in% this_run$fold)  %>% dplyr::select(one_of(this_run$vars_to_include_pruned %>% str_split(pattern=";", simplify =T) %>% as.vector())) #
fips <- xyid_all %>% dplyr::filter(fold %in% this_run$fold) %>% pull(fips)
xgboost_for_shap <- xgb.load(this_run$path_model)
shap_values <- SHAPforxgboost::shap.values(xgb_model = xgboost_for_shap , x_train =  x_train  %>% Rfast::data.frame.to_matrix(col.names=T ) )
shap_long2 <- shap.prep(xgb_model = xgboost_for_shap, x_train = x_train  %>% Rfast::data.frame.to_matrix(col.names=T ) ) #it needs column names
shap_long2$fips <- fips[shap_long2$ID]
shap_long2$ID = shap_long2$ID + max(shap_long1$ID) #move all the ID numbers up
shap_long2$fold <- 2
shap_int2 <- shap.prep.interaction(xgb_mod = xgboost_for_shap, x_train = x_train  %>% Rfast::data.frame.to_matrix(col.names=T )) #This one is trickier because it's an array

#Fold 3
this_run <- model_folds %>% dplyr::filter(fold==3, model_name==this_model_name) 
x_train <- xyid_all %>% dplyr::filter(fold %in% this_run$fold)  %>% dplyr::select(one_of(this_run$vars_to_include_pruned %>% str_split(pattern=";", simplify =T) %>% as.vector())) #
fips <- xyid_all %>% dplyr::filter(fold %in% this_run$fold) %>% pull(fips)
xgboost_for_shap <- xgb.load(this_run$path_model)
shap_values <- SHAPforxgboost::shap.values(xgb_model = xgboost_for_shap , x_train =  x_train  %>% Rfast::data.frame.to_matrix(col.names=T ) )
shap_long3 <- shap.prep(xgb_model = xgboost_for_shap, x_train = x_train  %>% Rfast::data.frame.to_matrix(col.names=T )  ) #it needs column names
shap_long3$fips <- fips[shap_long3$ID]
shap_long3$ID = shap_long3$ID + max(shap_long2$ID) #move all the ID numbers up
shap_long3$fold <- 3
shap_int3 <- shap.prep.interaction(xgb_mod = xgboost_for_shap, x_train = x_train  %>% Rfast::data.frame.to_matrix(col.names=T )) #This one is trickier because it's an array

#Fold 4
this_run <- model_folds %>% dplyr::filter(fold==4, model_name==this_model_name) 
x_train <- xyid_all %>% dplyr::filter(fold %in% this_run$fold)  %>% dplyr::select(one_of(this_run$vars_to_include_pruned %>% str_split(pattern=";", simplify =T) %>% as.vector())) #
fips <- xyid_all %>% dplyr::filter(fold %in% this_run$fold) %>% pull(fips)
xgboost_for_shap <- xgb.load(this_run$path_model)
shap_values <- SHAPforxgboost::shap.values(xgb_model = xgboost_for_shap , x_train =  x_train  %>% Rfast::data.frame.to_matrix(col.names=T ) )
shap_long4 <- shap.prep(xgb_model = xgboost_for_shap, x_train = x_train  %>% Rfast::data.frame.to_matrix(col.names=T )  ) #it needs column names
shap_long4$fips <- fips[shap_long4$ID]
shap_long4$ID = shap_long4$ID + max(shap_long3$ID) #move all the ID numbers up
shap_long4$fold <- 4
shap_int4 <- shap.prep.interaction(xgb_mod = xgboost_for_shap, x_train = x_train  %>% Rfast::data.frame.to_matrix(col.names=T )) #This one is trickier because it's an array

#Fold 5
this_run <- model_folds %>% dplyr::filter(fold==5, model_name==this_model_name) 
x_train <- xyid_all %>% dplyr::filter(fold %in% this_run$fold)  %>% dplyr::select(one_of(this_run$vars_to_include_pruned %>% str_split(pattern=";", simplify =T) %>% as.vector())) #
fips <- xyid_all %>% dplyr::filter(fold %in% this_run$fold) %>% pull(fips)
xgboost_for_shap <- xgb.load(this_run$path_model)
shap_values <- SHAPforxgboost::shap.values(xgb_model = xgboost_for_shap , x_train =  x_train  %>% Rfast::data.frame.to_matrix(col.names=T ) )
shap_long5 <- shap.prep(xgb_model = xgboost_for_shap, x_train = x_train  %>% Rfast::data.frame.to_matrix(col.names=T )  ) #it needs column names
shap_long5$fips <- fips[shap_long5$ID]
shap_long5$ID = shap_long5$ID + max(shap_long4$ID) #move all the ID numbers up
shap_long5$fold <- 5
shap_int5 <- shap.prep.interaction(xgb_mod = xgboost_for_shap, x_train = x_train  %>% Rfast::data.frame.to_matrix(col.names=T )) #This one is trickier because it's an array

#Fold 6
this_run <- model_folds %>% dplyr::filter(fold==6, model_name==this_model_name) 
x_train <- xyid_all %>% dplyr::filter(fold %in% this_run$fold)  %>% dplyr::select(one_of(this_run$vars_to_include_pruned %>% str_split(pattern=";", simplify =T) %>% as.vector())) #
fips <- xyid_all %>% dplyr::filter(fold %in% this_run$fold) %>% pull(fips)
xgboost_for_shap <- xgb.load(this_run$path_model)
shap_values <- SHAPforxgboost::shap.values(xgb_model = xgboost_for_shap , x_train =  x_train  %>% Rfast::data.frame.to_matrix(col.names=T ) )
shap_long6 <- shap.prep(xgb_model = xgboost_for_shap, x_train = x_train  %>% Rfast::data.frame.to_matrix(col.names=T )  ) #it needs column names
shap_long6$fips <- fips[shap_long6$ID]
shap_long6$ID = shap_long6$ID + max(shap_long5$ID) #move all the ID numbers up
shap_long6$fold <- 6
shap_int6 <- shap.prep.interaction(xgb_mod = xgboost_for_shap, x_train = x_train  %>% Rfast::data.frame.to_matrix(col.names=T )) #This one is trickier because it's an array



shap_long <- bind_rows(shap_long1,shap_long2,shap_long3,shap_long4,shap_long5,shap_long6)
dim(shap_long)

p_shap <- shap.plot.summary(shap_long ) #it'll still plot when you add more things to that df


p_load(abind)
#shap_int <- abind(shap_int1, shap_int2, shap_int3, shap_int4, shap_int5,shap_int6,along=1) #We have a problem now with interactions because they have different numbers of cols
#dim(shap_int)


```

```{r}
p_shap
```

#### Interacts

```{r}
#so what we basically want to do is cluster variables by how much they work together so that get turned into coherent groups
#
p_load(narray)
total_interaction <- narray::map(abs(shap_int), along=1, FUN=sum) #,  #apply(abs(shap_int), MARGIN=1, FUN=sum, simplify = T) # rowSums(abs(shap_int), dims = 2) #apply(abs(shap_int),MARGIN=1,sum)
dim(total_interaction) #

df <- rowSums(total_interaction) %>% as.data.frame() #The diagonal is by itself I think, so this includes both interactions and by self

total_interaction_nobias <- total_interaction[!rownames(total_interaction) %in% c('BIAS'),!colnames(total_interaction) %in% c('BIAS')]
diag(total_interaction_nobias) <- 0
summary(total_interaction_nobias %>% as.vector())
hist(log(total_interaction_nobias)) #You have to log it

#Ok given a model I think this tells us how variables works together to constribute to that models performance
total_interaction_inv <- 1/log(total_interaction_nobias) #log
total_interaction_inv[!is.finite(total_interaction_inv)] <- NA
total_interaction_d <- dist(total_interaction_inv)
hc_total_interaction <- hclust(total_interaction_d, method="ward.D2")
plot(hc_total_interaction)
p_load(ggdendro)
hcdata <- dendro_data(hc_total_interaction)
ggdendrogram(hcdata, rotate = TRUE, size = 2)

#What I think we should do now is think about how shap values are related to residuals
#So for every obs in the validation set we know what our residual is and what contributed most to it. We can think about variables that we take away and on average how much that would change in sample and out of sample performance


```

### Interpreting Features

#### Trump Support

Trump support has a monotonic but nonlinear relationship with expected
vaccine uptake. Any support from 0% to about 45% suggest much higher
+10% uptake. As percentage reaches parity and then increases, vaccine
uptake decreases nearly linearly to a minimum expected -12% uptake at
the highest levels of support.

The model trained on the coasts and predicted on the center of the
country always looks strange, it's always attenuated.

```{r}

var="donaldjtrump_2020"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)

```

```{r}
p
```

```{r}

var="donaldtrump_2016"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)

```

```{r}
p
```

#### poor_or_fair_health_perc_brfss2018

```{r}

var="poor_or_fair_health_perc_brfss2018"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)

```

```{r}
p
```

#### mammography_screening_percap2018

```{r}
var="mammography_screening_percap2018"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)



```

```{r}
p
```

#### active_physicians_per_100000_population_2018_aamc

```{r}
var="active_physicians_per_100000_population_2018_aamc"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)



```

```{r}
p
```

#### median_household_income_2018

```{r}
var="median_household_income_2018"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)



```

```{r}
p
```

#### white_perc

```{r}
var="white_perc"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)



```

```{r}
p
```

#### previous_child_vaccinated_perc

```{r}
var="previous_child_vaccinated_perc"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)



```

```{r}
p
```

#### flu_vaccinations_perc_medicare2018

```{r}
var="flu_vaccinations_perc_medicare2018"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)



```

```{r}
p
```

#### primary_care_physicians_percap_2018

```{r}
var="primary_care_physicians_percap_2018"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)



```

```{r}
p 
```

#### gdp_arts_entertainment_and_recreation

```{r}
var="gdp_arts_entertainment_and_recreation"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)



```

```{r}
p + xlim(0,3)
```

#### gdp_real_estate_and_rental_and_leasing

```{r}
var="gdp_real_estate_and_rental_and_leasing"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)



```

```{r}
p + xlim(0,25)
```

#### gdp_arts_entertainment_recreation_accommodation_and_food_services

```{r}
var="gdp_arts_entertainment_recreation_accommodation_and_food_services"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)



```

```{r}
p + xlim(0,10)
```

#### masking_never

```{r}
var="masking_never"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)



```

```{r}
p + xlim(0,0.5)
```

#### workplaces_percent_change_from_baseline

The more you stayed home the more that got vaccinated. Probably because
those were jobs that could.

```{r}
var="workplaces_percent_change_from_baseline"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)



```

```{r}
p #+ xlim(0,0.5)
```

#### black_perc

```{r}
var="gdp_educational_services_health_care_and_social_assistance"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)



```

```{r}
p + xlim(0,10)
```

#### black_perc

```{r}
var="black_perc"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)



```

```{r}
p
```

#### total_age65plus_perc

```{r}
var="total_age65plus_perc"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)



```

```{r}
p
```

#### percent_of_adults_with_a\_bachelors_degree_or_higher_2014_18

```{r}

var="percent_of_adults_with_a_bachelors_degree_or_higher_2014_18"
p <- SHAPforxgboost::shap.plot.dependence(data_long = shap_long, #created above
                           #data_int = shap_int,
                           x= var , y = var #, # y = "black_perc",  #ah it only shows up in some folds
                          # color_feature = F
                          ) + geom_point(aes(color=shap_long %>% dplyr::filter(variable==var) %>% dplyr::select(ID,fold) %>% distinct() %>% pull(fold)  ), size=0.1)


```

```{r}
p
```

#### 

```{r}
plot_data <- shap.prep.stack.data(shap_contrib = shap_values$shap_score, top_n = 8, n_groups = 8)
# you may choose to zoom in at a location, and set y-axis limit using `y_parent_limit`  
shap.plot.force_plot(plot_data, zoom_in_location = 100, y_parent_limit = c(-0.1,0.1))
```

### The role of variables in the no politics model

```{r, eval=F, echo=F}

model_folds <- all_fits %>% dplyr::select(fold, model_name, path_model,vars_to_include) %>% distinct()

this_run <- model_folds %>% dplyr::filter(fold==1, model_name=="urbanicity_race_medical_wealth") 

x_train <- xyid_all %>% dplyr::filter(fold %in% this_run$fold)  %>% dplyr::select(one_of(this_run$vars_to_include %>% str_split(pattern=";", simplify =T) %>% as.vector())) #something went wrong with the kmeans and they aren't balanced
dim(x_train)

xgboost_for_shap <- xgb.load(this_run$path_model)

p_load(SHAPforxgboost)
shap_values <- SHAPforxgboost::shap.values(xgb_model = xgboost_for_shap , x_train =  x_train  %>% Rfast::data.frame.to_matrix(col.names=T ) )
shap_long <- shap.prep(xgb_model = xgboost_for_shap, x_train = x_train  %>% Rfast::data.frame.to_matrix(col.names=T )  , top_n=50 ) #it needs column names
p <- shap.plot.summary(shap_long ) #these take longer and longer so we might want to downsample to a fixe number of points %>% sample_n(100000)
```

```{r}
p
```

```{r}
shap_int <- shap.prep.interaction(xgb_mod = xgboost_for_shap, x_train = x_train  %>% Rfast::data.frame.to_matrix(col.names=T ))

p <- shap.plot.dependence(data_long = shap_long, #created above
                           data_int = shap_int,
                           x= "trump_perc", # y = "black_perc", 
                           color_feature = "auto")
```

```{r}
p
```

## Look at Residuals

## Marginal Effects

## Interaction Effects

## Cluster Counties

# Step 8: Synthesize Competing Explainations

# Step 9: Unexplained Variation Remaining

# Conclusion

### Left Overs

Define some helper functions that will iterate over groups of variables
and save predictions.

```{r, message=F, result=F, eval=F}


#This finds the best hyperparamaters for that set of variables which might change as it gets smaller 
p_load("ParBayesianOptimization")
#We can pass whatever we want to this so we can do feature selection too
scoringFunction <- function(max_depth, min_child_weight, subsample) {
  
  Pars <- list( 
    booster = "gbtree"
    , eta = 0.1 #they picked a very low learning rate #lower eta is always better performing
    , max_depth = max_depth
    , min_child_weight = min_child_weight
    , subsample = subsample
    , objective = "reg:squarederror" #"reg:squarederror"
    , eval_metric = "rmse"
  )
  
  xgbcv <- xgb.cv(
    params = Pars
    , data = d_train
    , nround = 2000
    , folds = Folds
    , prediction = TRUE
    , showsd = TRUE
    , early_stopping_rounds = 10
    , maximize = F
    , verbose = 0,
    nthread=120
    )
  
  return(
    list( 
      #make sure you allign all this to the actual metric you're using
      Score = min(xgbcv$evaluation_log$test_rmse_mean)*-1 #For some reason it can only maximize, so we have to -1 this 
      , nrounds = xgbcv$best_iteration
    )
  )
}

p_load(xgboost)
p_load(Rfast)
p_load(testit)
fit_subset_model <- function(model_name='',vars_to_include=c('')) {

  print(model_name)
  path_predictions <- glue::glue("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/test_predictions/{model_name}.parquet")
  if(file.exists(path_predictions)){
    print("Already exists, skipping")
    return()
  }    
  
  yid_all <- NULL
  xid_all <- NULL
  
  
  tictoc::tic()
  yid_all <- xyid_all %>% dplyr::select(fold, fips,fips_state, uptake_max)  #This subsets it to just our dv , plus Ids
  xid_all <- xyid_all %>% dplyr::select(fold,   fips, fips_state,one_of(vars_to_include))  #this to just the vars we want to include, plus IDs
  setdiff(vars_to_include,names(xid_all)) %>% print()
  testit::assert(length(setdiff(vars_to_include,names(xid_all)))==0) #no variables are missing
    
  #So it first loops over all 6 test sets
  predictions_list <- list()
  for(i in 1:6){

    #Fold is what we're excluding
    yid_train <- yid_all %>% dplyr::filter(!fold %in% c(i)) #this subsets it to everything but the test fold
    yid_test <- yid_all %>% dplyr::filter(fold %in% c(i))
    
    xid_train <- xid_all %>% dplyr::filter(!fold %in% c(i)) #this subsets it to everything but the test fold
    xid_test <- xid_all %>% dplyr::filter(fold %in% c(i))    
    
    #This will then do 3 fold cross validation within just the training data and splitting randomly on state
    #fips_state <- xid_train$fips_state %>% unique() %>% sample() #shuffle the list
    #cv_folds <- rep_len(1:3, length.out=length(fips_state)); names(cv_folds) <- fips_state
    #cv_folds[as.character(xid_train$fips_state)]
    #cv_folds <- rep_len(1:5, length.out=length(fips_state)); names(cv_folds) <- fips_state
    remaining_folds <- xid_train$fold %>% unique()
    
    #folds list provides a possibility to use a list of pre-defined CV folds (each element must be a vector of test fold's indices). When folds are supplied, the nfold and stratified parameters are ignored.
    Folds <- list(
        Fold1 = which(xid_train$fold==remaining_folds[1]) #There are 5 folds left to choose from, here we fit on everything but the first one
      , Fold2 = which(xid_train$fold==remaining_folds[2]) #Everything but the second one
      , Fold3 = which(xid_train$fold==remaining_folds[3])
      , Fold4 = which(xid_train$fold==remaining_folds[4])
      , Fold5 = which(xid_train$fold==remaining_folds[5])
    )
    #We further pick splits by state for CV

    y_train <- NULL; y_valid<-NULL;y_test<-NULL #Nuke everything just to make sure
    x_train <- NULL; x_valid<-NULL;x_test<-NULL
    d_train <- NULL; d_valid <- NULL; d_test <- NULL

    y_train <- yid_train %>% dplyr::select(uptake_max) 
    y_test <-  yid_test %>% dplyr::select(uptake_max)
    
    #grid <- rbind( 
    #    data.frame(max_depth=6, min_child_weight=15, subsample=1 ) #, #on median subsample 1 wins, you have to vary the other two to find slightly better outcomes
    #    #data.frame(max_depth=6, min_child_weight=15, subsample=0.9 ),
    #    #data.frame(max_depth=6, min_child_weight=15, subsample=0.8 ),
    #    #data.frame(max_depth=6, min_child_weight=15, subsample=0.7 ),
    #    #data.frame(max_depth=6, min_child_weight=15, subsample=0.6 ),
    #    #data.frame(max_depth=6, min_child_weight=15, subsample=0.5 ),
    #    #data.frame(max_depth=6, min_child_weight=15, subsample=0.4 ),
    #    #data.frame(max_depth=6, min_child_weight=15, subsample=0.3 )#,
    #    #data.frame(max_depth=6, min_child_weight=15, subsample=0.3 ),
    #    #data.frame(max_depth=6, min_child_weight=15, subsample=0.3 )
    #)
          
    #We then loop over variables, kicking out whichever one contributes the most to out of sample overfitting
    vars_to_include_pruned = vars_to_include
    kick_out<- NA
    for(m in 1:(length(vars_to_include)-1)){ #It requires at least two variables
      
      x_train <- xid_train %>% dplyr::select(one_of(vars_to_include_pruned)) #our xtrain is fit to increasingly small sets of vars
      x_test <- xid_test %>% dplyr::select(one_of(vars_to_include_pruned))
  
      d_train <- xgb.DMatrix( x_train %>% Rfast::data.frame.to_matrix(),  label=y_train %>% Rfast::data.frame.to_matrix(col.names=T )); 
      d_test <- xgb.DMatrix( x_test %>% Rfast::data.frame.to_matrix(),  label=y_test %>% Rfast::data.frame.to_matrix(col.names=T ));

      bounds <- list( 
        #eta = c(0.01,0.3),
        max_depth = c(2L, 10L)
        , min_child_weight = c(1, 30)
        , subsample = c(0.25, 1)
      )
      
      #set.seed(1234)
      #optObj <- bayesOpt(
      #  verbose =0,
      #  FUN = scoringFunction,
      #  , bounds = bounds
      #  , initPoints = 10 #increasing this to 30 throws an err
      #  , iters.n = 1
      #  #, iters.k=3
      #  #, acqThresh=0.7
      #  #, otherHalting = list(minUtility = 0.1) #stop runnin when the utility of another one drops below a threshold
      #  , plotProgress = F #Set to false when running notebook
      #)
      # grid_result <- grid %>% dplyr::mutate(test_rmse_mean=NA)
      # for(k in 1:nrow(grid)){
      #     pars_try <- list( 
      #       booster = "gbtree"
      #       , eta = 0.3 #getBestPars(optObj)$eta #they picked a very low learning rate
      #       , max_depth = grid$max_depth[k]
      #       , min_child_weight = grid$min_child_weight[k]
      #       , subsample = grid$subsample[k]
      #       , objective = "reg:squarederror"
      #       , eval_metric = "rmse"
      #     )
      #   
      #     #Using the tuned hyperparamaters above fit one last cv model to measure how features did
      #     xgbcv_temp <- NULL
      #     xgbcv_temp <- xgb.cv(
      #       params = pars_try
      #       , data = d_train
      #       , nround = 2000
      #       , folds = Folds
      #       , prediction = TRUE
      #       , showsd = TRUE
      #       , early_stopping_rounds = 10
      #       , maximize = F
      #       , verbose = 0
      #       ,nthread=120
      #       ,callbacks = list(cb.cv.predict(save_models = TRUE))
      #       )   
      #      grid_result$test_rmse_mean[k] <-  xgbcv_temp$evaluation_log[xgbcv_temp$best_iteration]$test_rmse_mean
      # }
      # grid_result_best <- grid_result %>% dplyr::filter(test_rmse_mean==min(test_rmse_mean))

      #optObj$scoreSummary
      #getBestPars(optObj)
      
      #optObj$scoreSummary %>% ggplot(aes(x=min_child_weight, y=subsample, color=Score)) + geom_point(size=4)
      #optObj$scoreSummary %>% ggplot(aes(x=min_child_weight, y=subsample, fill=Score, z=Score))+ geom_tile()  

      
      #nrounds_best = optObj$scoreSummary %>% arrange(desc(Score)) %>% pull(nrounds) %>% .[1]
      #expected_rmse = optObj$scoreSummary %>% arrange(desc(Score)) %>% pull(Score) %>% .[1]*-1
      
      pars_best <- list( 
          booster = "gbtree"
          , eta = 0.01 #getBestPars(optObj)$eta #they picked a very low learning rate #lower learning rate for the final one
          , max_depth = 6 #grid_result_best$max_depth
          , min_child_weight = 15 #grid_result_best$min_child_weight
          , subsample = 1 #grid_result_best$subsample
          , objective = "reg:squarederror"
          , eval_metric = "rmse"
        )
        
      #Using the tuned hyperparamaters above fit one last cv model to measure how features did
      xgbcv <- NULL
      xgbcv <- xgb.cv(
        params = pars_best
        , data = d_train
        , nround = 2000
        , folds = Folds
        , prediction = TRUE
        , showsd = TRUE
        , early_stopping_rounds = 10
        , maximize = F
        , verbose = 0
        ,nthread=120
        ,callbacks = list(cb.cv.predict(save_models = TRUE))
      )    
      
      
      #Measure how features did
      #Loop over each validation hold out and calculate how residuals change if we remove a single var
      variable_contributions_list <- list()
      for(j in 1:5){
        #xgbcv$models[[j]] #It's got a handle so we're going to have to do our shap work
        shap_marginal <- predict(xgbcv$models[[j]],  xgb.DMatrix( x_train[Folds[j] %>% unlist(),] %>% Rfast::data.frame.to_matrix() ) , predcontrib=T  ) #get shap values for model j on validation hold out j
        #When predinteraction = TRUE and it is not a multiclass setting, the output is a 3d array with dimensions c(nrow, num_features + 1, num_features + 1). The off-diagonal (in the last two dimensions) elements represent different features interaction contributions. The array is symmetric WRT the last two dimensions. The "+ 1" columns corresponds to bias. Summing this array along the last dimension should produce practically the same result as predict with predcontrib = TRUE. For a multiclass case, a list of num_class elements is returned, where each element is such an array.
        #shap_interact <- predict(xgbcv$models[[j]],  xgb.DMatrix( x_train[Folds[j] %>% unlist(),] %>% Rfast::data.frame.to_matrix() ) , predinteraction=T  ) #get shap values for model j on validation hold out j
        #dim(shap_interact)
        #shap_interact[1,,] #this is symetric, supposedly summing this whole matrix of itneractions should return the same value as marginal
        #sum(shap_interact[1,1,]) approx equal shap_marginal[1,1], which it does
        #So what i think we might be able to say is that we know its marginal effect
        #And we can calculate how much help or damage it does in conjunction with one additional variable, so we can look for pairs of variables that look particularly helpful or damaging
        #I think we still want the marginal here because if we do identify a pair of damaging variables, they might still help in interaction with others. And so we really do want to add up all the help and hurt and see if it's net pos or neg
        
        #dim(shap_marginal) #467  56
        BIAS0=shap_marginal[,ncol(shap_marginal)][1] #That last column is the bias
        shap_marginal <- shap_marginal[,-ncol(shap_marginal)]
        colnames(shap_marginal) <- colnames(x_train)
        y <-  y_train[Folds[j] %>% unlist(),]
        y$y_hat <- rowSums(shap_marginal) + BIAS0 #Compute the Yhat for the model at each observation
        y$residual <- y$y_hat- y$uptake_max #calculate the residual
        #mean(y$residual)
        residual_new <- y$residual - shap_marginal #What would the residual be if we subtracted off the contribution from that variable?
        residual_change_square <- y$residual^2-residual_new^2 #Did that make the residual bigger or smaller? #Changed this to reduction in square error. Otherwise we could flip neg and not know it.
        #so bigger numbers here mean taking away would lead to bigger residuals on average, and taking away would mean smaller
        #mean_residual_change_square <- colMeans(residual_change_square) %>% 
        #                                round(4) %>% #rounding to 4 requires a var to improve predictions by at least a hundredth of a percent
        #                                sort()  
        #variable_contributions_df <- mean_residual_change_square %>% as.data.frame() %>% rownames_to_column(var="variable") %>% rename(mean_residual_change_square='.')
        variable_contributions_list[[j]] <- residual_change_square  %>% as.data.frame()
      }
      
      current_best <- xgbcv$evaluation_log$test_rmse_mean[xgbcv$best_iteration]
            
      #Look to see if any variables left make validation net worse or neutral
      variable_contributions_df <- bind_rows(variable_contributions_list)  %>% #ok this is now the change in mean squared error from that variable for every observation in every validation set
                                   colMeans() %>% #this is now the mean change in mean squared error
                                   #round() %>% #apparently the changes to mean squared error are quite small
                                   #group_by(variable) %>% 
                                   #  summarise(change_to_residual_mean=mean(change_to_residual) %>% round(4)) %>% #This is meaning again over the folds, is that what we want to do?
                                   # ungroup() %>% 
                                   as.data.frame() %>% rownames_to_column(var="variable") %>% rename(mean_residual_change_square='.') %>%
                                   arrange(mean_residual_change_square) %>%
                                   mutate(fold=i) %>%
                                   mutate(pruning=m) %>%
                                   mutate(vars_to_include_n=length(vars_to_include) ) %>%
                                   mutate(vars_to_include_pruned_n=length(vars_to_include_pruned) ) %>%
                      
                                   mutate(vars_to_include=paste(vars_to_include, collapse=";") ) %>%
                                   mutate(vars_to_include_pruned=paste(vars_to_include_pruned, collapse=";") ) %>%
                                   mutate(current_validation_rmse=current_best )
      #variable_contributions_df %>% ggplot(aes(x=change_to_residual,y=variable)) + geom_boxplot()

      
      variable_contributions_df_to_kill <- variable_contributions_df %>% dplyr::filter(mean_residual_change_square>=0) %>% arrange(mean_residual_change_square %>% desc()) #it's reversed now so we want to punish variables that drive up squared error
      
      current_best <- xgbcv$evaluation_log$test_rmse_mean[xgbcv$best_iteration]
      print(glue::glue("Current best is {current_best}") )

      #If none do then break out of this loop with the final model
      if(nrow(variable_contributions_df_to_kill)==0){break}
    
      #Withold that worst variable from the set and loop all over again
      kick_out <- variable_contributions_df_to_kill$variable[1] #
      print(glue::glue("I'm kicking out {kick_out}") )
      vars_to_include_pruned <- setdiff(vars_to_include_pruned,kick_out) #change vars to include by removing that one and then loop back over
      
      path_hyperparameter_search <- glue::glue("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/validation_predictions/{model_name}_testfold_{i}_lastkicked_{m}.parquet")  #had to change it from variable names because the file names got too long
      arrow::write_parquet(variable_contributions_df, path_hyperparameter_search)   
      
      
      # path_hyperparameter_search <- glue::glue("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/validation_predictions/{model_name}_testfold_{i}_lastkicked_{kick_out}.parquet")
      # hyperparameter_search <- grid_result %>% 
      #                          mutate(model_name=model_name, vars_to_include=paste(vars_to_include, collapse=";"), 
      #                                 vars_to_include_pruned=paste(vars_to_include_pruned, collapse=";"),
      #                                 test_fold=i
      #                                 )
      # arrow::write_parquet(hyperparameter_search, path_hyperparameter_search)   
      
    }
    
    print(glue::glue("################################################################################################I finished pruning the model"))
    #I finished pruning the model

    #Refitting the last run just with all the data, no validation holdout
    xgboost_best <- NULL
    xgboost_best <-  xgb.train(params=pars_best,data=d_train, nrounds=xgbcv$best_iteration, verbose = 0, nthread=120)
    path_model <- glue::glue("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/models/{model_name}{i}.xgboost")
    xgb.save(xgboost_best, fname=path_model)

    p_load(rjson)
    predictions <- NULL
    predictions <- yid_test %>% 
                   mutate(y_hat=predict(xgboost_best, d_test)) %>%
                   mutate(model_name=model_name) %>%
                   mutate(path_model=path_model) %>%
                   mutate(parameters=pars_best %>% toJSON(indent=0, method="C" ) ) %>%
                   mutate(nrounds_best=xgbcv$best_iteration ) %>%
                   mutate(expected_rmse=current_best ) %>%
                   mutate(training_n=nrow(x_train) ) %>%
                   mutate(vars_to_include_n=length(vars_to_include) ) %>%
                   mutate(vars_to_include_pruned_n=length(vars_to_include_pruned) ) %>%
      
                   mutate(vars_to_include=paste(vars_to_include, collapse=";") ) %>%
                   mutate(vars_to_include_pruned=paste(vars_to_include_pruned, collapse=";") )
    
    predictions_list[[as.character(i)]] <- predictions
    
  }

    pred_all <- bind_rows(predictions_list) %>% mutate(residual=y_hat-uptake_max) 
    arrow::write_parquet(pred_all, path_predictions)

   tictoc::toc() %>% print()

}

```

# Fit just a model without feature selection, fast as possible

```{r, eval=F}

yid_all <- xyid_all %>% dplyr::select(fold, fips,fips_state, uptake_max)  #This subsets it to just our dv , plus Ids
xid_all <- xyid_all #%>% dplyr::select(fold,   fips, fips_state,one_of(vars_to_include))  #this to just the vars we want to include, plus IDs
  
#We try to do as much beforehand as possible

#1
yid_train1 <- yid_all %>% dplyr::filter(!fold %in% c(1)) #this subsets it to everything but the test fold
yid_test1 <- yid_all %>% dplyr::filter(fold %in% c(1))
xid_train1 <- xid_all %>% dplyr::filter(!fold %in% c(1)) #this subsets it to everything but the test fold
xid_test1 <- xid_all %>% dplyr::filter(fold %in% c(1)) 

remaining_folds1 <- xid_train1$fold %>% unique()
Folds1 <- list(
    Fold1 = which(xid_train1$fold==remaining_folds1[1]) #There are 5 folds left to choose from, here we fit on everything but the first one
  , Fold2 = which(xid_train1$fold==remaining_folds1[2]) #Everything but the second one
  , Fold3 = which(xid_train1$fold==remaining_folds1[3])
  , Fold4 = which(xid_train1$fold==remaining_folds1[4])
  , Fold5 = which(xid_train1$fold==remaining_folds1[5])
)

#2
yid_train2 <- yid_all %>% dplyr::filter(!fold %in% c(2)) #this subsets it to everything but the test fold
yid_test2 <- yid_all %>% dplyr::filter(fold %in% c(2))
xid_train2 <- xid_all %>% dplyr::filter(!fold %in% c(2)) #this subsets it to everything but the test fold
xid_test2 <- xid_all %>% dplyr::filter(fold %in% c(2)) 

remaining_folds2 <- xid_train2$fold %>% unique()
Folds2 <- list(
    Fold1 = which(xid_train2$fold==remaining_folds2[1]) #There are 5 folds left to choose from, here we fit on everything but the first one
  , Fold2 = which(xid_train2$fold==remaining_folds2[2]) #Everything but the second one
  , Fold3 = which(xid_train2$fold==remaining_folds2[3])
  , Fold4 = which(xid_train2$fold==remaining_folds2[4])
  , Fold5 = which(xid_train2$fold==remaining_folds2[5])
)

#3
yid_train3 <- yid_all %>% dplyr::filter(!fold %in% c(3)) #this subsets it to everything but the test fold
yid_test3 <- yid_all %>% dplyr::filter(fold %in% c(3))
xid_train3 <- xid_all %>% dplyr::filter(!fold %in% c(3)) #this subsets it to everything but the test fold
xid_test3 <- xid_all %>% dplyr::filter(fold %in% c(3)) 

remaining_folds3 <- xid_train3$fold %>% unique()
Folds3 <- list(
    Fold1 = which(xid_train3$fold==remaining_folds3[1]) #There are 5 folds left to choose from, here we fit on everything but the first one
  , Fold2 = which(xid_train3$fold==remaining_folds3[2]) #Everything but the second one
  , Fold3 = which(xid_train3$fold==remaining_folds3[3])
  , Fold4 = which(xid_train3$fold==remaining_folds3[4])
  , Fold5 = which(xid_train3$fold==remaining_folds3[5])
)

#4
yid_train4 <- yid_all %>% dplyr::filter(!fold %in% c(4)) #this subsets it to everything but the test fold
yid_test4 <- yid_all %>% dplyr::filter(fold %in% c(4))
xid_train4 <- xid_all %>% dplyr::filter(!fold %in% c(4)) #this subsets it to everything but the test fold
xid_test4 <- xid_all %>% dplyr::filter(fold %in% c(4)) 

remaining_folds4 <- xid_train4$fold %>% unique()
Folds4 <- list(
    Fold1 = which(xid_train4$fold==remaining_folds4[1]) #There are 5 folds left to choose from, here we fit on everything but the first one
  , Fold2 = which(xid_train4$fold==remaining_folds4[2]) #Everything but the second one
  , Fold3 = which(xid_train4$fold==remaining_folds4[3])
  , Fold4 = which(xid_train4$fold==remaining_folds4[4])
  , Fold5 = which(xid_train4$fold==remaining_folds4[5])
)

#5
yid_train5 <- yid_all %>% dplyr::filter(!fold %in% c(5)) #this subsets it to everything but the test fold
yid_test5 <- yid_all %>% dplyr::filter(fold %in% c(5))
xid_train5 <- xid_all %>% dplyr::filter(!fold %in% c(5)) #this subsets it to everything but the test fold
xid_test5 <- xid_all %>% dplyr::filter(fold %in% c(5)) 

remaining_folds5 <- xid_train5$fold %>% unique()
Folds5 <- list(
    Fold1 = which(xid_train5$fold==remaining_folds5[1]) #There are 5 folds left to choose from, here we fit on everything but the first one
  , Fold2 = which(xid_train5$fold==remaining_folds5[2]) #Everything but the second one
  , Fold3 = which(xid_train5$fold==remaining_folds5[3])
  , Fold4 = which(xid_train5$fold==remaining_folds5[4])
  , Fold5 = which(xid_train5$fold==remaining_folds5[5])
)

#6
yid_train6 <- yid_all %>% dplyr::filter(!fold %in% c(6)) #this subsets it to everything but the test fold
yid_test6 <- yid_all %>% dplyr::filter(fold %in% c(6))
xid_train6 <- xid_all %>% dplyr::filter(!fold %in% c(6)) #this subsets it to everything but the test fold
xid_test6 <- xid_all %>% dplyr::filter(fold %in% c(6)) 

remaining_folds6 <- xid_train6$fold %>% unique()
Folds6 <- list(
    Fold1 = which(xid_train6$fold==remaining_folds6[1]) #There are 5 folds left to choose from, here we fit on everything but the first one
  , Fold2 = which(xid_train6$fold==remaining_folds6[2]) #Everything but the second one
  , Fold3 = which(xid_train6$fold==remaining_folds6[3])
  , Fold4 = which(xid_train6$fold==remaining_folds6[4])
  , Fold5 = which(xid_train6$fold==remaining_folds6[5])
)



pars_best <- list( 
    booster = "gbtree"
    , eta = 0.3 #getBestPars(optObj)$eta #they picked a very low learning rate #lower learning rate for the final one
    , max_depth = 6 #grid_result_best$max_depth
    , min_child_weight = 15 #grid_result_best$min_child_weight
    , subsample = 1 #grid_result_best$subsample
    , objective = "reg:squarederror"
    , eval_metric = "rmse"
  )
try({detach("package:tidylog", unload=TRUE)})
fit_model <- function(model_name='',vars_to_include=c('')){
    path_predictions <- glue::glue("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/test_predictions/{model_name}.parquet")
    if(file.exists(path_predictions)){return()}
    vars_to_include_collapsed <- paste(vars_to_include, collapse=";")
    
    #1
    d_train1 <- xgb.DMatrix( xid_train1 %>% dplyr::select(one_of(vars_to_include)) %>% Rfast::data.frame.to_matrix(),  label=yid_train1 %>% dplyr::select(uptake_max) %>% Rfast::data.frame.to_matrix(col.names=T )); 
    d_test1 <- xgb.DMatrix( xid_test1 %>% dplyr::select(one_of(vars_to_include)) %>% Rfast::data.frame.to_matrix(),  label=yid_test1 %>% dplyr::select(uptake_max) %>% Rfast::data.frame.to_matrix(col.names=T ));
    #We still have to cv to get interations
    xgbcv1 <- xgb.cv(params = pars_best, data = d_train1, nround = 2000, folds = Folds1, prediction = F, showsd = F, early_stopping_rounds = 10, maximize = F, verbose = 0,nthread=128)
    xgboost_best1 <-  xgb.train(params=pars_best,data=d_train1, nrounds=xgbcv1$best_iteration, verbose = 0, nthread=128)
    r1 <- yid_test1 %>% mutate(rmse_validation=xgbcv1$evaluation_log$test_rmse_mean[xgbcv1$best_iteration]) %>% mutate(y_hat=predict(xgboost_best1, d_test1)) %>% mutate(model_name=model_name) %>% mutate(vars_to_include=vars_to_include_collapsed )

    #2
    d_train2 <- xgb.DMatrix( xid_train2 %>% dplyr::select(one_of(vars_to_include)) %>% Rfast::data.frame.to_matrix(),  label=yid_train2 %>% dplyr::select(uptake_max) %>% Rfast::data.frame.to_matrix(col.names=T )); 
    d_test2 <- xgb.DMatrix( xid_test2 %>% dplyr::select(one_of(vars_to_include)) %>% Rfast::data.frame.to_matrix(),  label=yid_test2 %>% dplyr::select(uptake_max) %>% Rfast::data.frame.to_matrix(col.names=T ));
    #We still have to cv to get interations
    xgbcv2 <- xgb.cv(params = pars_best, data = d_train2, nround = 2000, folds = Folds2, prediction = F, showsd = F, early_stopping_rounds = 10, maximize = F, verbose = 0,nthread=128)
    xgboost_best2 <-  xgb.train(params=pars_best,data=d_train2, nrounds=xgbcv2$best_iteration, verbose = 0, nthread=128)
    r2 <- yid_test2 %>% mutate(rmse_validation=xgbcv2$evaluation_log$test_rmse_mean[xgbcv2$best_iteration]) %>%  mutate(y_hat=predict(xgboost_best2, d_test2)) %>% mutate(model_name=model_name) %>% mutate(vars_to_include=vars_to_include_collapsed ) 

    #3
    d_train3 <- xgb.DMatrix( xid_train3 %>% dplyr::select(one_of(vars_to_include)) %>% Rfast::data.frame.to_matrix(),  label=yid_train3 %>% dplyr::select(uptake_max) %>% Rfast::data.frame.to_matrix(col.names=T )); 
    d_test3 <- xgb.DMatrix( xid_test3 %>% dplyr::select(one_of(vars_to_include)) %>% Rfast::data.frame.to_matrix(),  label=yid_test3 %>% dplyr::select(uptake_max) %>% Rfast::data.frame.to_matrix(col.names=T ));
    #We still have to cv to get interations
    xgbcv3 <- xgb.cv(params = pars_best, data = d_train3 , nround = 2000, folds = Folds3 , prediction = F, showsd = F, early_stopping_rounds = 10, maximize = F, verbose = 0,nthread=128)
    xgboost_best3 <-  xgb.train(params=pars_best,data=d_train3 , nrounds=xgbcv3$best_iteration, verbose = 0, nthread=128)
    r3 <- yid_test3 %>% mutate(rmse_validation=xgbcv3$evaluation_log$test_rmse_mean[xgbcv3$best_iteration]) %>%  mutate(y_hat=predict(xgboost_best3, d_test3)) %>% mutate(model_name=model_name) %>% mutate(vars_to_include=vars_to_include_collapsed )
  
    #4
    d_train4 <- xgb.DMatrix( xid_train4 %>% dplyr::select(one_of(vars_to_include)) %>% Rfast::data.frame.to_matrix(),  label=yid_train4 %>% dplyr::select(uptake_max) %>% Rfast::data.frame.to_matrix(col.names=T )); 
    d_test4 <- xgb.DMatrix( xid_test4 %>% dplyr::select(one_of(vars_to_include)) %>% Rfast::data.frame.to_matrix(),  label=yid_test4 %>% dplyr::select(uptake_max) %>% Rfast::data.frame.to_matrix(col.names=T ));
    #We still have to cv to get interations
    xgbcv4 <- xgb.cv(params = pars_best, data = d_train4 , nround = 2000, folds = Folds4 , prediction = F, showsd = F, early_stopping_rounds = 10, maximize = F, verbose = 0,nthread=128)
    xgboost_best4 <-  xgb.train(params=pars_best,data=d_train4 , nrounds=xgbcv4$best_iteration, verbose = 0, nthread=128)
    r4 <- yid_test4 %>% mutate(rmse_validation=xgbcv4$evaluation_log$test_rmse_mean[xgbcv4$best_iteration]) %>%  mutate(y_hat=predict(xgboost_best4, d_test4)) %>% mutate(model_name=model_name) %>% mutate(vars_to_include=vars_to_include_collapsed ) 
    
    #5
    d_train5 <- xgb.DMatrix( xid_train5 %>% dplyr::select(one_of(vars_to_include)) %>% Rfast::data.frame.to_matrix(),  label=yid_train5 %>% dplyr::select(uptake_max) %>% Rfast::data.frame.to_matrix(col.names=T )); 
    d_test5 <- xgb.DMatrix( xid_test5 %>% dplyr::select(one_of(vars_to_include)) %>% Rfast::data.frame.to_matrix(),  label=yid_test5 %>% dplyr::select(uptake_max) %>% Rfast::data.frame.to_matrix(col.names=T ));
    #We still have to cv to get interations
    xgbcv5 <- xgb.cv(params = pars_best, data = d_train5 , nround = 2000, folds = Folds5 , prediction = F, showsd = F, early_stopping_rounds = 10, maximize = F, verbose = 0,nthread=128)
    xgboost_best5 <-  xgb.train(params=pars_best,data=d_train5 , nrounds=xgbcv5$best_iteration, verbose = 0, nthread=128)
    r5 <- yid_test5 %>% mutate(rmse_validation=xgbcv5$evaluation_log$test_rmse_mean[xgbcv5$best_iteration]) %>%  mutate(y_hat=predict(xgboost_best5, d_test5)) %>% mutate(model_name=model_name) %>% mutate(vars_to_include=vars_to_include_collapsed ) 
    
    #
    d_train6 <- xgb.DMatrix( xid_train6 %>% dplyr::select(one_of(vars_to_include)) %>% Rfast::data.frame.to_matrix(),  label=yid_train6 %>% dplyr::select(uptake_max) %>% Rfast::data.frame.to_matrix(col.names=T )); 
    d_test6 <- xgb.DMatrix( xid_test6 %>% dplyr::select(one_of(vars_to_include)) %>% Rfast::data.frame.to_matrix(),  label=yid_test6 %>% dplyr::select(uptake_max) %>% Rfast::data.frame.to_matrix(col.names=T ));
    #We still have to cv to get interations
    xgbcv6 <- xgb.cv(params = pars_best, data = d_train6 , nround = 2000, folds = Folds6 , prediction = F, showsd = F, early_stopping_rounds = 10, maximize = F, verbose = 0,nthread=128)
    xgboost_best6 <-  xgb.train(params=pars_best,data=d_train6 , nrounds=xgbcv6$best_iteration, verbose = 0, nthread=128)
    r6 <- yid_test6 %>% mutate(rmse_validation=xgbcv6$evaluation_log$test_rmse_mean[xgbcv6$best_iteration]) %>%  mutate(y_hat=predict(xgboost_best6, d_test6)) %>% mutate(model_name=model_name) 
    
    bind_rows(r1,r2,r3,r4,r5,r6) %>% arrow::write_parquet(path_predictions)

}



```

# Left overs

```{r, eval=F}

      
      x_imputed_interactions_train1 <- model.matrix( ~.^2, data=x_imputed_train1 ) %>% as.data.frame() %>% janitor::clean_names()  %>% cbind(x_imputed_train1) %>% Rfast::data.frame.to_matrix(col.names=T) 
      x_imputed_interactions_test1 <- model.matrix( ~.^2, data=x_imputed_test1 ) %>% as.data.frame() %>% janitor::clean_names()  %>% cbind(x_imputed_test1) %>% Rfast::data.frame.to_matrix(col.names=T) 
      dim(x_imputed_interactions_train1)

n_vars <- length(vars_to_include)
pars_rf <- list( 
  booster = "gbtree"
  , num_parallel_tree=1000 #this matters and you really do need to up the n to make sure it settles out
  , eta = 1
  , colsample_bynode=sqrt(n_vars)/n_vars # colsample_bynode
  , max_depth = 10 #grid_result_best$max_depth
  #, min_child_weight = 15 #grid_result_best$min_child_weight
  , subsample = 0.66 #grid_result_best$subsample
  , objective = "reg:squarederror"
  , eval_metric = "rmse"
)

n_vars_interactions <- n_vars^2/2 + n_vars
pars_rf_interactions <- list( 
  booster = "gbtree"
  , num_parallel_tree=1000 #this matters and you really do need to up the n to make sure it settles out
  , eta = 1
  , colsample_bynode=sqrt(n_vars_interactions)/n_vars_interactions # colsample_bynode
  , max_depth = 10 #grid_result_best$max_depth
  #, min_child_weight = 15 #grid_result_best$min_child_weight
  , subsample = 0.66 #grid_result_best$subsample
  , objective = "reg:squarederror"
  , eval_metric = "rmse"
)

        
    #Xgboost
    #iter train_rmse_mean train_rmse_std test_rmse_mean test_rmse_std
    #773       0.0233796    0.001653241      0.0603118   0.006734411
    #xgboost1 <- xgb.cv(params = pars_best, data = xgb.DMatrix( x_train1 %>% Rfast::data.frame.to_matrix(col.names=T),  label=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T)) , nround = 3000, 
    #                   folds = Folds1, prediction = F, showsd = F, early_stopping_rounds = 10, maximize = F, verbose = 1,nthread=128)
    
    #xgboost1_nocv  <-  xgb.train(params=pars_best, data= xgb.DMatrix( x_train1 %>% Rfast::data.frame.to_matrix(col.names=T),  label=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T)) ,
    #                             nrounds=xgboost1$best_iteration, verbose = 0, nthread=128)
    #id_test1$y_hat_xgboost <- predict(xgboost1_nocv, xgb.DMatrix( x_imputed_test1 %>% Rfast::data.frame.to_matrix(col.names=T),  label=y_test1 %>% Rfast::data.frame.to_matrix(col.names=T )) )
    

    #Xgboost with imputation and interactions  
    xgboost1_imputed_interaction <- xgb.cv(params = pars_best, data = xgb.DMatrix( x_imputed_interactions_train1 %>% Rfast::data.frame.to_matrix(col.names=T),  
                                                                                   label=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T)) , nround = 3000, 
                       folds = Folds1, prediction = F, showsd = F, early_stopping_rounds = 10, maximize = F, verbose = 1,nthread=128)
    
    xgboost1_nocv_imputed_interaction  <-  xgb.train(params=pars_best, data= xgb.DMatrix( x_imputed_interactions_train1 %>% Rfast::data.frame.to_matrix(col.names=T),
                                                                                          label=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T)) ,
                                 nrounds=xgboost1_imputed_interaction$best_iteration, verbose = 0, nthread=128)
    id_test1$y_hat_xgboost_imputed_interaction <- predict(xgboost1_nocv_imputed_interaction, xgb.DMatrix( x_imputed_interactions_test1 %>% Rfast::data.frame.to_matrix(col.names=T),  label=y_test1 %>% Rfast::data.frame.to_matrix(col.names=T )) )
    

    p_load(keras)
    model = keras_model_sequential() %>% 
       layer_batch_normalization() %>%
       layer_dropout(rate=0.5) %>%
       layer_dense(units=64, activation="relu", input_shape=x_imputed_train1 %>% ncol(),
                   kernel_regularizer = regularizer_l2(0.000001)
       ) %>% 
       layer_batch_normalization() %>%
       layer_dropout(rate=0.5) %>%
       #layer_dense(units=1024, activation = "selu") %>% 
       #layer_batch_normalization() %>%
       #layer_dropout(rate=0.5) %>%
       #layer_dense(units=8, activation = "relu") %>% 
       layer_dense(units=1, activation="linear")
    
    metric_mean_pred <- custom_metric("root_mean_squared_error", function(y_true, y_pred) {
      metric_mean_squared_error(y_true, y_pred)^0.5
    })
    

      
    #We're going to cv across training folds
    fit_list <- list()
    for(validate_fold in id_train1$fold %>% unique() ){
      print(validate_fold)
      condition <- !id_train1$fold==validate_fold
      #compile in the loop to reset it
      model %>% compile(
         loss = "mse",
         optimizer =  optimizer_adam(lr = 0.01), #starting at 0.01 really does seem to matter
         metrics = metric_mean_pred #list("metric_mean_squared_error")
      )
          
      fit1 <- model %>% fit(x=x_imputed_train1[condition,] %>% Rfast::data.frame.to_matrix(col.names=T),
                    y=y_train1[condition,] %>% Rfast::data.frame.to_matrix(col.names=T),
                    epochs = 1000,
                    verbose = 1,
                    batch_size=8,
                    validation_data = list(x_imputed_train1[!condition,]%>% Rfast::data.frame.to_matrix(col.names=T), y_train1[!condition,]%>% Rfast::data.frame.to_matrix(col.names=T)),
                    view_metrics=F, #still crashes rstudio y
                    callbacks= list(callback_early_stopping(monitor = "val_loss", patience=50,
                                                            restore_best_weights=T),
                                    callback_reduce_lr_on_plateau(monitor = "val_loss", factor = 0.1))
      )
      fit_list[[as.character(validate_fold)]] <- as.data.frame(fit1$metrics) %>% rownames_to_column( var = "epoch")
    }
    fit_list_df <- bind_rows(fit_list)
    fit_list_df %>% ggplot(aes(x=epoch %>% as.numeric() %>% as.factor(), y=val_root_mean_squared_error)) + geom_boxplot()
    fit_list_df %>% ggplot(aes(x=epoch %>% as.numeric() %>% as.factor(), y=lr)) + geom_boxplot()
    #Ok so when we're done cv-ing, we're going to have to create a learning rate schedule based on this
    #Learning rate schedule
    learning_rate_schedule <- fit_list_df %>% group_by(epoch = as.numeric(epoch)) %>% summarise(lr_median= median(lr)) %>% arrange(epoch)
    max_epochs <- (learning_rate_schedule$epoch %>% max()) - 49  #subtract off our patience
    
    #https://github.com/rstudio/tensorflow/issues/252
    schedule_function <- function(epoch_index, lr){
      learning_rate_schedule %>% filter(epoch==epoch_index+1) %>% pull(lr_median) #will fail if more epochs than we have data for, that's intentional
    }
    model %>% compile(
         loss = "mse",
         optimizer =  optimizer_adam(lr = 0.01), #starting at 0.01 really does seem to matter
         metrics = metric_mean_pred #list("metric_mean_squared_error")
     )
    fit_final <- model %>% 
                        fit(x=x_imputed_train1 %>% Rfast::data.frame.to_matrix(col.names=T), #full training data
                        y=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T),
                        epochs = max_epochs,
                        verbose = 1,
                        batch_size=8,
                        view_metrics=F, #still crashes rstudio y
                        callbacks= list(callback_learning_rate_scheduler(schedule_function))
                        ) 
    
    id_test1$y_hat_nn <- predict(object=model, x=x_imputed_test1 %>% Rfast::data.frame.to_matrix(col.names=T))[,1] 


    
    
    #p_load(DALEX)
    #p_load(rSAFE)
    #explainer_lasso <- explain(lasso_1, data = x_imputed_train1 %>% Rfast::data.frame.to_matrix(col.names=T), y = y_train1 %>% Rfast::data.frame.to_matrix(col.names=T), label = "lasso", verbose = T)
    #explainer_lasso
    
    #safe_extractor_lasso <- safe_extraction(explainer_lasso, penalty = "MBIC", verbose = T, interactions=T)
    #print(safe_extractor_lasso)

    #plot(safe_extractor_lasso, variable = "percent_of_adults_with_a_bachelors_degree_or_higher_2014_18")
    #x_imputed_train1_transformed <- safely_transform_data(safe_extractor_lasso, x_imputed_train1 %>% Rfast::data.frame.to_matrix(col.names=T), verbose = T)

    #vars <- safely_select_variables(safe_extractor_lasso, x_imputed_train1_transformed, y = y_train1 %>% Rfast::data.frame.to_matrix(col.names=T), verbose = F) #this fails for some reason
    
    #    Measure: Mean-Squared Error 
    #
    #      Lambda Index  Measure        SE Nonzero
    #min 0.002811    37 0.003798 0.0003343      36 #0.06162792 fewer features slightly worse performance
    #1se 0.007128    27 0.004131 0.0003391      23 #0.06427286 one fewer feature, worse performance
    #lasso_1_transformed = cv.glmnet(x=x_imputed_train1_transformed %>% Rfast::data.frame.to_matrix(col.names=T), y=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T) ,  foldid = id_train1$fold %>% droplevels() %>% as.integer())
    #coef(lasso_1_transformed, s = "lambda.1se") %>% as.matrix() %>% as.data.frame() %>%  mutate(s1=s1 %>% round(4)) %>% filter(s1!=0) %>% arrange(s1)  %>% View()

    #      Lambda Index  Measure        SE Nonzero
    #min 0.005521    59 0.003834 0.0003784      36
    #1se 0.010108    46 0.004182 0.0003354      22 #rmse 0.06466838 so slightly worse rmse thanks to overfitting
    #lasso_interactions_1 = cv.glmnet(x=x_imputed_interactions_train1 %>% Rfast::data.frame.to_matrix(col.names=T), y=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T),  foldid = id_train1$fold %>% droplevels() %>% as.integer())
    #coef(lasso_interactions_1, s = "lambda.1se") %>% as.matrix() %>% as.data.frame() %>%  mutate(s1=s1 %>% round(4)) %>% filter(s1!=0) %>% arrange(s1)  %>% View()
    
    #id_test1$y_hat_lasso_imputed_interactions <- predict(lasso_interactions_1, newx=x_imputed_interactions_test1 %>% Rfast::data.frame.to_matrix(col.names=T), s = c("lambda.1se"), gamma="lambda.1se")[,1] #Test predictions 

    ############## Random Forests    
# 
#     #RF no imputation or interaction
#     library(xgboost)
#     #iter train_rmse_mean train_rmse_std test_rmse_mean test_rmse_std
#     #1        0.038826    0.001039676      0.0697906   0.009005324   #also slightly worse rmse thanks to overfitting
#     rf1 <- xgb.cv(params = pars_rf, data = xgb.DMatrix( x_train1 %>% Rfast::data.frame.to_matrix(col.names=T),  label=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T)) , nround = 1, folds = Folds1, prediction = F, showsd = F, early_stopping_rounds = 10, maximize = F, verbose = 0,nthread=128)
#     
#     rf1_nocv <-  xgb.train(params=pars_rf,data= xgb.DMatrix( x_train1 %>% Rfast::data.frame.to_matrix(col.names=T),  label=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T)) , nrounds=1, verbose = 0, nthread=128)
#     id_test1$y_hat_rf <- predict(rf1_nocv, xgb.DMatrix( x_imputed_test1 %>% Rfast::data.frame.to_matrix(col.names=T),  label=y_test1 %>% Rfast::data.frame.to_matrix(col.names=T )) )
#     
#     #RF with imputation
#     # iter train_rmse_mean train_rmse_std test_rmse_mean test_rmse_std
#     #1       0.0389614   0.0009984746      0.0696786    0.00803094 #slightly better from imputation but very slightly
#     rf1_imputed <- xgb.cv(params = pars_rf, data = xgb.DMatrix( x_imputed_train1 %>% Rfast::data.frame.to_matrix(col.names=T),  label=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T)) , nround = 1, folds = Folds1, prediction = F, showsd = F, early_stopping_rounds = 10, maximize = F, verbose = 0,nthread=128)
#     
#     rf1_nocv_imputed  <-  xgb.train(params=pars_rf,data= xgb.DMatrix( x_imputed_train1 %>% Rfast::data.frame.to_matrix(col.names=T),  label=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T)) , nrounds=1, verbose = 0, nthread=128)
#     id_test1$y_hat_rf_imputed <- predict(rf1_nocv_imputed, xgb.DMatrix( x_imputed_test1 %>% Rfast::data.frame.to_matrix(col.names=T),  label=y_test1 %>% Rfast::data.frame.to_matrix(col.names=T )) )
#     
#     #RF with interaction
#     #iter train_rmse_mean train_rmse_std test_rmse_mean test_rmse_std
#     #1       0.0359888    0.001072445      0.0686588   0.007671737  #Interaction only very slightly reduces
#     rf1_imputed_interaction <- xgb.cv(params = pars_rf_interactions, data = xgb.DMatrix( x_imputed_interactions_train1 %>% Rfast::data.frame.to_matrix(col.names=T),  label=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T)) , nround = 1, folds = Folds1, prediction = F, showsd = F, early_stopping_rounds = 10, maximize = F, verbose = 0,nthread=128)
#     
#     rf1_nocv_imputed_interactions  <-  xgb.train(params=pars_rf_interactions,data= xgb.DMatrix( x_imputed_interactions_train1 %>% Rfast::data.frame.to_matrix(col.names=T),  label=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T)) , nrounds=1, verbose = 0, nthread=128)
#     id_test1$y_hat_rf_imputed_interactions <- predict(rf1_nocv_imputed_interactions, xgb.DMatrix( x_imputed_interactions_test1 %>% Rfast::data.frame.to_matrix(col.names=T),  label=y_test1 %>% Rfast::data.frame.to_matrix(col.names=T )) )

    ############## Xgboosts    
            
    # 
    # p_load("ParBayesianOptimization")
    # p_load(xgboost)
    # #Bayesian search
    # scoringFunction <- function(max_depth, min_child_weight, subsample,colsample_bynode) {
    #   
    #   Pars <- list( 
    #     booster = "gbtree"
    #     , eta = 0.1 #they picked a very low learning rate #lower eta is always better performing
    #     , max_depth = max_depth
    #     , min_child_weight = min_child_weight
    #     , subsample = subsample
    #     , colsample_bynode = colsample_bynode
    #     , objective = "reg:squarederror" #"reg:squarederror"
    #     , eval_metric = "rmse"
    #   )
    #   
    #   xgbcv <- xgb.cv(
    #     params = Pars
    #     , data = xgb.DMatrix( x_imputed_interactions_train1 %>% Rfast::data.frame.to_matrix(col.names=T),  label=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T) ) #imputed interactions
    #     , nround = 2000
    #     , folds = Folds1
    #     , prediction = TRUE
    #     , showsd = TRUE
    #     , early_stopping_rounds = 10
    #     , maximize = F
    #     , verbose = 0,
    #     nthread=120
    #   )
    #   
    #   return(
    #     list( 
    #       #make sure you allign all this to the actual metric you're using
    #       Score = min(xgbcv$evaluation_log$test_rmse_mean)*-1 #For some reason it can only maximize, so we have to -1 this 
    #       , nrounds = xgbcv$best_iteration
    #     )
    #   )
    # }
    # 
    # bounds <- list( 
    #   max_depth = c(2L, 10L) #tree depth
    #   , min_child_weight = c(1, 30) #number of samples required for splitting
    #   , subsample = c(0.25, 1) #subsample rows
    #   , colsample_bynode=c(0.1,1) #subsample features
    # )
    # 
    # 
    # set.seed(1234)
    # optObj <- bayesOpt(
    #   verbose =1,
    #   FUN = scoringFunction,
    #   , bounds = bounds
    #   , initPoints = 10 #increasing this to 30 throws an err
    #   , iters.n = 400
    #   #, iters.k=1
    #   , acqThresh=0.7
    #   , otherHalting = list(minUtility = 0.05, timeLimit = 1200) #stop runnin when the utility of another one drops below a threshold or takes more than 5 minutes
    #   , plotProgress = T #Set to false when running notebook
    # )
    # 
    # optObj$scoreSummary
    # getBestPars(optObj)
    # 
    # optObj$scoreSummary %>% ggplot(aes(x=min_child_weight, y=subsample, color=Score)) + geom_point(size=4)
    # optObj$scoreSummary %>% ggplot(aes(x=min_child_weight, y=subsample, fill=Score, z=Score))+ geom_tile()  
    # 
    # nrounds_best = optObj$scoreSummary %>% arrange(desc(Score)) %>% pull(nrounds) %>% .[1]
    # expected_rmse = optObj$scoreSummary %>% arrange(desc(Score)) %>% pull(Score) %>% .[1]*-1
    # 
    # #Basically what this shows us is there's a surface here where you want to stop over fitting but only so much so if you go smaller on one value you have to larger on another
    # grid <- rbind( 
    #     data.frame(max_depth=5, min_child_weight=23.032852, subsample=0.7747657, colsample_bynode=0.1482689 ) , #The best bayesian
    #     data.frame(max_depth=5, min_child_weight=22.918150, subsample=0.7797239, colsample_bynode=0.3684861) , #The best bayesian
    #     data.frame(max_depth=6, min_child_weight=24.442437, subsample=0.8324971, colsample_bynode=0.3077250) , #The best bayesian
    #     data.frame(max_depth=6, min_child_weight=1, subsample=1, colsample_bynode=1 ) , #The default
    #     data.frame(max_depth=10, min_child_weight=1, subsample=1, colsample_bynode=1 ) , #The overfit
    #     data.frame(max_depth=2, min_child_weight=30, subsample=1, colsample_bynode=1 ) , #The underfit
    #     data.frame(max_depth=6, min_child_weight=1, subsample=1, colsample_bynode=0.1 ) , #The diffuse
    #     data.frame(max_depth=6, min_child_weight=1, subsample=0.33, colsample_bynode=1 ) , #The noisy
    #     data.frame(max_depth=6, min_child_weight=1, subsample=0.33, colsample_bynode=0.1 ) , #The diffuse noisy
    #     data.frame(max_depth=10, min_child_weight=1, subsample=0.33, colsample_bynode=0.1 ) , #The diffuse noisy deeper
    #     data.frame(max_depth=6, min_child_weight=1, subsample=0.25, colsample_bynode=0.05 ) , #The really diffuse noisy
    #     data.frame(max_depth=6, min_child_weight=1, subsample=1, colsample_bynode=0.05 ) , #The really diffuse noisy
    #     data.frame(max_depth=6, min_child_weight=1, subsample=0.5, colsample_bynode=0.5 ) , #The medium 1
    #     data.frame(max_depth=10, min_child_weight=30, subsample=0.4, colsample_bynode=1 ) , #The medium 4
    #     data.frame(max_depth=5, min_child_weight=3, subsample=0.5, colsample_bynode=0.5 ) , #The medium 5
    #     data.frame(max_depth=8, min_child_weight=15, subsample=0.6, colsample_bynode=0.4 )  #The medium 6
    #   )
    # 
    #    #there are some that are just uniformly bad, but the random seed changes who is the best which is kind of not what you want
    #    grid_result_list <- list()
    #    for( run in 1:3){
    #      grid_result <- grid %>% dplyr::mutate(test_rmse_mean=NA)
    #      for(k in 1:nrow(grid)){
    #         print(k)
    #          pars_try <- list( 
    #            booster = "gbtree"
    #            , eta = 0.05 #getBestPars(optObj)$eta #they picked a very low learning rate
    #            , max_depth = grid$max_depth[k]
    #            , min_child_weight = grid$min_child_weight[k]
    #            , subsample = grid$subsample[k]
    #            , colsample_bynode = grid$colsample_bynode[k]
    #            , objective = "reg:squarederror"
    #            , eval_metric = "rmse"
    #          )
    #        
    #          #Using the tuned hyperparamaters above fit one last cv model to measure how features did
    #          xgbcv_temp <- NULL
    #          xgbcv_temp <- xgb.cv(
    #            params = pars_try
    #            , data = xgb.DMatrix( x_train1 %>% Rfast::data.frame.to_matrix(col.names=T),  label=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T))
    #            , nround = 2000
    #            , folds = Folds1
    #            , prediction = F
    #            , showsd = TRUE
    #            , early_stopping_rounds = 10
    #            , maximize = F
    #            , verbose = 0
    #            ,nthread=128
    #            #,callbacks = list(cb.cv.predict(save_models = TRUE))
    #            )   
    #           grid_result$test_rmse_mean[k] <-  xgbcv_temp$evaluation_log[xgbcv_temp$best_iteration]$test_rmse_mean
    #      }
    #      grid_result_list[[as.character(run)]] <- grid_result
    #    }
    #   grid_result_df <- bind_rows(grid_result_list)
    #   grid_result_df %>% group_by(max_depth,min_child_weight,subsample,colsample_bynode) %>% summarise(test_rmse_mean=mean(test_rmse_mean)) %>% arrange(test_rmse_mean) #every time I run this I get different answers
    #   grid_result_best <- grid_result %>% dplyr::filter(test_rmse_mean==min(test_rmse_mean))
    
    
    

     #Explain rf
     
     explainer_rf <- explain(rf1_nocv_imputed,
                     data = x_imputed_train1 %>% Rfast::data.frame.to_matrix(col.names=T),
                     y =y_train1 %>% Rfast::data.frame.to_matrix(col.names=T),
                     label = "rf")
      safe_extractor_rf <- safe_extraction(explainer_rf, penalty = "MBIC", verbose = T, interactions=T, inter_param=0.05,inter_threshold=0.05) #ok it's the interactions that are failing, really pisses me off but ya interactions cause an error for nn
      print(safe_extractor_rf)
      safe_extractor_rf$interaction_effects 
      
      x_imputed_train1_transformed_rf <- safely_transform_data(safe_extractor_rf, x_imputed_train1 %>% Rfast::data.frame.to_matrix(col.names=T), verbose = T)
      x_imputed_test1_transformed_rf <- safely_transform_data(safe_extractor_rf, x_imputed_test1 %>% Rfast::data.frame.to_matrix(col.names=T), verbose = T)

      lasso_1_transformed_rf = cv.glmnet(x=x_imputed_train1_transformed_rf %>% Rfast::data.frame.to_matrix(col.names=T), y=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T) ,  foldid = id_train1$fold %>% droplevels() %>% as.integer())
      lasso_1_transformed_rf_coefs_min <- coef(lasso_1_transformed_rf, s = "lambda.min") %>% as.matrix() %>% as.data.frame() %>%  mutate(s1=s1 %>% round(4)) %>% filter(s1!=0) %>% arrange(s1)    
      lasso_1_transformed_rf_coefs_min %>% View()   
            
      id_test1$y_hat_lasso_imputed_transformed_rf_min  <- predict(lasso_1_transformed_rf, newx=x_imputed_test1_transformed_rf %>% Rfast::data.frame.to_matrix(col.names=T), s = c("lambda.min"), gamma="lambda.min")[,1] #Test predictions 

     
          
     #Explain keras
     explainer_nn <- explain(model,
                     data = x_imputed_train1 %>% Rfast::data.frame.to_matrix(col.names=T),
                     y =y_train1 %>% Rfast::data.frame.to_matrix(col.names=T),
                     label = "nn")
      safe_extractor_nn <- safe_extraction(explainer, penalty = "MBIC", verbose = T, interactions=F) #ok it's the interactions that are failing, really pisses me off but ya interactions cause an error for nn
      print(safe_extractor_nn)

      x_imputed_train1_transformed_nn <- safely_transform_data(safe_extractor_nn, x_imputed_train1 %>% Rfast::data.frame.to_matrix(col.names=T), verbose = T)
      x_imputed_test1_transformed_nn <- safely_transform_data(safe_extractor_nn, x_imputed_test1 %>% Rfast::data.frame.to_matrix(col.names=T), verbose = T)

      lasso_1_transformed_nn = cv.glmnet(x=x_imputed_train1_transformed_nn %>% Rfast::data.frame.to_matrix(col.names=T), y=y_train1 %>% Rfast::data.frame.to_matrix(col.names=T) ,  foldid = id_train1$fold %>% droplevels() %>% as.integer())
      lasso_1_transformed_nn_coefs_min <- coef(lasso_1_transformed_nn, s = "lambda.min") %>% as.matrix() %>% as.data.frame() %>%  mutate(s1=s1 %>% round(4)) %>% filter(s1!=0) %>% arrange(s1)    
      lasso_1_transformed_nn_coefs_min %>% View()   
            
      id_test1$y_hat_lasso_imputed_transformed_nn_min  <- predict(lasso_1_transformed_nn, newx=x_imputed_test1_transformed_nn %>% Rfast::data.frame.to_matrix(col.names=T), s = c("lambda.min"), gamma="lambda.min")[,1] #Test predictions 

      # make a studio for the model
      #modelStudio(explainer) #Looks like it taks about 10 min or more. But it's doing every single thing, quite a benchmark

```

#### Random Forest Version

Theoretical grouping of variables, what we intended to measure Marginal
contribution, what they

```{r, message=F, result=F}


p_load(xgboost)
p_load(Rfast)
p_load(testit)
fit_subset_model <- function(model_name='',vars_to_include=c('')) {

  print(model_name)
  path_predictions <- glue::glue("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/test_predictions/{model_name}.parquet")
  if(file.exists(path_predictions)){
    print("Already exists, skipping")
    return()
  }    
  
  yid_all <- NULL
  xid_all <- NULL
  
  
  tictoc::tic()
  yid_all <- xyid_all %>% dplyr::select(fold, fips,fips_state, uptake_max)  #This subsets it to just our dv , plus Ids
  xid_all <- xyid_all %>% dplyr::select(fold,   fips, fips_state,one_of(vars_to_include))  #this to just the vars we want to include, plus IDs
  setdiff(vars_to_include,names(xid_all)) %>% print()
  testit::assert(length(setdiff(vars_to_include,names(xid_all)))==0) #no variables are missing
    
  #So it first loops over all 6 test sets
  predictions_list <- list()
  for(i in 1:6){

    #Fold is what we're excluding
    yid_train <- yid_all %>% dplyr::filter(!fold %in% c(i)) #this subsets it to everything but the test fold
    yid_test <- yid_all %>% dplyr::filter(fold %in% c(i))
    
    xid_train <- xid_all %>% dplyr::filter(!fold %in% c(i)) #this subsets it to everything but the test fold
    xid_test <- xid_all %>% dplyr::filter(fold %in% c(i))    
    
    #This will then do 3 fold cross validation within just the training data and splitting randomly on state
    #fips_state <- xid_train$fips_state %>% unique() %>% sample() #shuffle the list
    #cv_folds <- rep_len(1:3, length.out=length(fips_state)); names(cv_folds) <- fips_state
    #cv_folds[as.character(xid_train$fips_state)]
    #cv_folds <- rep_len(1:5, length.out=length(fips_state)); names(cv_folds) <- fips_state
    remaining_folds <- xid_train$fold %>% unique()
    
    #folds list provides a possibility to use a list of pre-defined CV folds (each element must be a vector of test fold's indices). When folds are supplied, the nfold and stratified parameters are ignored.
    Folds <- list(
        Fold1 = which(xid_train$fold==remaining_folds[1]) #There are 5 folds left to choose from, here we fit on everything but the first one
      , Fold2 = which(xid_train$fold==remaining_folds[2]) #Everything but the second one
      , Fold3 = which(xid_train$fold==remaining_folds[3])
      , Fold4 = which(xid_train$fold==remaining_folds[4])
      , Fold5 = which(xid_train$fold==remaining_folds[5])
    )
    #We further pick splits by state for CV

    y_train <- NULL; y_valid<-NULL;y_test<-NULL #Nuke everything just to make sure
    x_train <- NULL; x_valid<-NULL;x_test<-NULL
    d_train <- NULL; d_valid <- NULL; d_test <- NULL

    y_train <- yid_train %>% dplyr::select(uptake_max) 
    y_test <-  yid_test %>% dplyr::select(uptake_max)

      #We then loop over variables, kicking out whichever one contributes the most to out of sample overfitting
      x_train <- xid_train %>% dplyr::select(one_of(vars_to_include)) #our xtrain is fit to increasingly small sets of vars
      x_test <- xid_test %>% dplyr::select(one_of(vars_to_include))
      d_train <- xgb.DMatrix( x_train %>% Rfast::data.frame.to_matrix(),  label=y_train %>% Rfast::data.frame.to_matrix(col.names=T )); 
      d_test <- xgb.DMatrix( x_test %>% Rfast::data.frame.to_matrix(),  label=y_test %>% Rfast::data.frame.to_matrix(col.names=T ));    

      #This takes no time at all 
      library(randomForestSRC)
      tictoc::tic()
        rf <- rfsrc(formula = uptake_max ~ . , data= cbind(x_train,  y_train) %>% as.data.frame() , ntree = 100, na.action ="na.impute")
      rf
      tictoc::toc()
      library(Metrics)
      Metrics::rmse(rf$predicted.oob , y_train$uptake_max) #Actually has a pretty low rmse 0.052, ah because it's using all of it, not cross validating with the folds
      
      #Something is wrong with xgboost
      #RF https://xgboost.readthedocs.io/en/latest/tutorials/rf.html
      pars_rf <- list( 
        booster = "gbtree"
        , num_parallel_tree=20000 #this matters and you really do need to up the n to make sure it settles out
        , eta = 1
        , colsample_bytree=sqrt(ncol(d_train))/ncol(d_train) # colsample_bynode
        , max_depth = 10 #grid_result_best$max_depth
        #, min_child_weight = 15 #grid_result_best$min_child_weight
        , subsample = 0.66 #grid_result_best$subsample
        , objective = "reg:squarederror"
        , eval_metric = "rmse"
      )
      
      #We don't really need to do CV because we don't care about how it performs. We can see it's a little worse, we' just using this as a fast in sample interaction check
      tictoc::tic()
      xgbcv <- NULL
      xgbcv <- xgb.train(
        params = pars_rf
        , data = d_train
        , nrounds = 1
        #, folds = Folds
        #, prediction = TRUE
        #, showsd = TRUE
        #, early_stopping_rounds = 10
        #, maximize = F
        , verbose = 0
        ,nthread=128
        #,callbacks = list(cb.cv.predict(save_models = TRUE))
       )    #0.074622 the random forest isn't too bad 0.074
     xgbcv     
     
     
     #So one way to think about this is marginal effects, we group variables by how they push the same observations in the same direction by the same amount
     tictoc::toc() #4 seconds for 1k
      shap_marginal <- predict(xgbcv,  d_train, predcontrib=T  )[,-105] #[,-(ncol(x_train)+1)] #last column is the bias
      colnames(shap_marginal) <- colnames(x_train)
      dim(shap_marginal)
      cor(shap_marginal[,'white_perc'] , shap_marginal[,'black_perc']) #-0.07550175
       Heatmap(shap_marginal %>% cor(), row_dend_reorder = TRUE, column_dend_reorder = TRUE, column_names_rot = 45,
           #row_names_max_width = max_text_width(rownames(feature_interactions_matrix_cor) ), 
           column_names_gp=  gpar(fontsize = 8),
           row_names_gp=  gpar(fontsize = 8),
           clustering_method_rows="ward.D2",
           clustering_method_columns="ward.D2"
       )

     #Or we might wan tto think about this as conditional effects, we group variables when their effect conditional on other things is similar. So after we condition on wealth, what things point the same way
     #This is a second order effect? Comparing each bivariate interaction and making sure they point the same way?
     #That top left corner is basically race, recent politics, and urbanity. Once you condition out wealth, all those things basically capture the same thing is what this is saying. That actually makes a lot of sense to me.
     #The bottom right is basically wealth lots of travel, education, entertainment
     #The only thing is correlations are super weak, so our distance tree is very shallow.
     tictoc::tic()
      shap_interaction <- predict(xgbcv,  d_train, predinteraction=T  )
     tictoc::toc() #1 min for 1k, 1.7min for 2k, so sublinearly
     #We can cluster observations by how the features and feature interactions think about them
     #And we can cluster features by how they interact with each other
     n_features=dim(shap_interaction)[2]-1 #the last one is the bias I think
     n_obs=dim(shap_interaction)[1]
     #shap_interaction[1:n_obs,1,] #This is feature 1's interaction with every other variable for every obs
     #shap_interaction[1:n_obs,1,] %>% as.vector()
     #shap_interaction[1:n_obs,1,] %>% t()
     shape <- shap_interaction[1,,] %>% lower.tri(diag = F)
     #shap_interaction[1,,][shape]
     #shap_interaction[1:n_obs,1,1:n_features] %>% dim() #this is the the first feature's contribution in interaction with every other feature for every obs
     #temp <- shap_interaction[1:n_obs,1,1:n_features]  %>% as.data.frame()
     #colnames(temp) <- colnames(x_train)
     #summary(temp$gdp_all_industry_total)
     #summary(temp$gdp_private_industries)
     
     feature_interactions_matrix <- do.call(rbind, lapply(1:n_features, FUN=function(i){ shap_interaction[1:n_obs,i,1:n_features] %>% as.vector() } ) )
     dim(feature_interactions_matrix) #This is feature x (obs x interaction)

     #This begs the question about third order interactions, but I guess that's what running full models is for. This gets us started as far as clustering variables into groups
     
     feature_interactions_matrix_t <- feature_interactions_matrix %>% t(); colnames(feature_interactions_matrix_t) <- colnames(x_train)
     dim(feature_interactions_matrix_t)
     cor(feature_interactions_matrix_t[,'white_perc'] , feature_interactions_matrix_t[,'black_perc']) #0.04599981

     #feature_interactions_matrix_cor <- feature_interactions_matrix %>% t() %>% cor()
     #diag(feature_interactions_matrix_cor) <- NA
     #install.packages('heatmaply')
     
     #library(devtools)
     #install_github("jokergoo/ComplexHeatmap")
     #Ok I think I understand this now
     #When they're close by, they tend to push in the same direction
     #When they're far apart they tend to push in opposite directions, for the same observations
     #So for example, top left of this heatmap is trump2020 also known as percent white or percent black
     #Bottom right of this map is wealth of a county also known as arts per capita, amount science, etc.
     #So these are people who are trump voters but also have enough money or wealth to get vaccinated. Clustering first on similarity to remove redundancy and then picking clusters on difference to provide interaction
     #That race/vs trump2020 cluster, you can see that race doesn't negatively correlated with much, it's mostly zeros, its trump that negatively correlates with a lot, although black percent does too a bit.
     library(ComplexHeatmap)
     Heatmap(feature_interactions_matrix_t %>% cor(), row_dend_reorder = TRUE, column_dend_reorder = TRUE, column_names_rot = 45,
             #row_names_max_width = max_text_width(rownames(feature_interactions_matrix_cor) ), 
             column_names_gp=  gpar(fontsize = 8),
             row_names_gp=  gpar(fontsize = 8),
             clustering_method_rows="ward.D2",
             clustering_method_columns="ward.D2",
             row_names_max_width=max_text_width(
        rownames(feature_interactions_matrix_t), 
        gp = gpar(fontsize = 8)
    )
    )
     
     #library(heatmaply)
     #heatmaply_cor(
    #    feature_interactions_matrix_cor,
    #    xlab = "Features",
    #    ylab = "Features",
    #    k_col = 2,
    #    k_row = 2
    #  )
     
     feature_interactions_matrix_cor_dist <- feature_interactions_matrix_t %>% cor() %>% dist()
     #summary(feature_interactions_matrix_cor_dist)
     hc_feature_interactions_matrix <- hclust(feature_interactions_matrix_cor_dist, method="ward.D2")
     plot(hc_feature_interactions_matrix)
     
     #shap_interaction[2,,]
     #dim(shap_interaction) #2229  105  105
     #Can we just calculate distance for each obs and then add them up?
     #shap_interaction[1,,] #
          
    #Iterate until vars_to_include_pruned doesn't change
    vars_to_include_pruned=vars_to_include
    for(k in 1:10){
      #We then loop over variables, kicking out whichever one contributes the most to out of sample overfitting
      x_train <- xid_train %>% dplyr::select(one_of(vars_to_include_pruned)) #our xtrain is fit to increasingly small sets of vars
      x_test <- xid_test %>% dplyr::select(one_of(vars_to_include_pruned))
      d_train <- xgb.DMatrix( x_train %>% Rfast::data.frame.to_matrix(),  label=y_train %>% Rfast::data.frame.to_matrix(col.names=T )); 
      d_test <- xgb.DMatrix( x_test %>% Rfast::data.frame.to_matrix(),  label=y_test %>% Rfast::data.frame.to_matrix(col.names=T ));
      
      variable_contributions_list <- list()
      for(m in 1:(10)){ #Number of shuffles to try
          print(m)
          x_train_shuffled <- bind_cols(x_train,x_train %>% sample_frac(1) %>% rename_all(~paste0(., "_shuffled")) )
          columns_to_sample_perc <- runif(1,.25,1)
          x_train_shuffled <- x_train_shuffled[,runif(ncol(x_train_shuffled))<columns_to_sample_perc]
          d_train_shuffled <- xgb.DMatrix( x_train_shuffled %>% Rfast::data.frame.to_matrix(),  label=y_train %>% Rfast::data.frame.to_matrix(col.names=T )); 
    
          xgbcv <- NULL
          xgbcv <- xgb.cv(
            params = pars_best
            , data = d_train_shuffled
            , nround = 2000
            , folds = Folds
            , prediction = TRUE
            , showsd = TRUE
            , early_stopping_rounds = 10
            , maximize = F
            , verbose = 0
            ,nthread=128
            ,callbacks = list(cb.cv.predict(save_models = TRUE))
          )    
    
          for(j in 1:5){
            shap_marginal <- predict(xgbcv$models[[j]],  xgb.DMatrix( x_train_shuffled[Folds[j] %>% unlist(),] %>% Rfast::data.frame.to_matrix() ) , predcontrib=T  ) #get shap values for model j on validation hold out j
            BIAS0=shap_marginal[,ncol(shap_marginal)][1] #That last column is the bias
            shap_marginal <- shap_marginal[,-ncol(shap_marginal)]
            colnames(shap_marginal) <- colnames(x_train_shuffled)
            y <-  y_train[Folds[j] %>% unlist(),]
            y$y_hat <- rowSums(shap_marginal) + BIAS0 #Compute the Yhat for the model at each observation
            y$residual <- y$y_hat- y$uptake_max #calculate the residual
            residual_new <- y$residual - shap_marginal #What would the residual be if we subtracted off the contribution from that variable?
            residual_change_square <- y$residual^2-residual_new^2 #Did that make the residual bigger or smaller? #Changed this to reduction in square error. Otherwise we could flip neg and not know it.
            variable_contributions_list[[paste(m,j)]] <- residual_change_square  %>% as.data.frame()
          }
        }
        #current_best <- xgbcv$evaluation_log$test_rmse_mean[xgbcv$best_iteration]
        variable_contributions_df <- bind_rows(variable_contributions_list)  %>% #ok this is now the change in mean squared error from that variable for every observation in every validation set
                                     colMeans(na.rm=T) %>% #this is now the mean change in mean squared error
                                     #round() %>% #apparently the changes to mean squared error are quite small
                                     #group_by(variable) %>% 
                                     #  summarise(change_to_residual_mean=mean(change_to_residual) %>% round(4)) %>% #This is meaning again over the folds, is that what we want to do?
                                     # ungroup() %>% 
                                     as.data.frame() %>% rownames_to_column(var="variable") %>% rename(mean_residual_change_square='.') %>%
                                     arrange(mean_residual_change_square) %>% 
                                     mutate(shuffled=variable %>% stringr::str_detect("_shuffled$") %>% as.numeric())
        
        variable_contributions_df_tokeep <- variable_contributions_df %>% filter(cumsum(shuffled)==0)
        if( all(variable_contributions_df_tokeep$variable==vars_to_include_pruned )){ #if the keep variable set doesn't change break out of this particular for loop
          print("Done pruning #####"); next
        }
        vars_to_include_pruned <- variable_contributions_df_tokeep$variable
    }
    
    
      
      
                                   mutate(test_fold=i) %>%
                                   mutate(pruning=m) %>%
                                   mutate(vars_to_include_n=length(vars_to_include) ) %>%
                                   mutate(vars_to_include_pruned_n=length(vars_to_include_pruned) ) %>%
                      
                                   mutate(vars_to_include=paste(vars_to_include, collapse=";") ) %>%
                                   mutate(vars_to_include_pruned=paste(vars_to_include_pruned, collapse=";") ) %>%
                                   mutate(current_validation_rmse=current_best )

      variable_contributions_df_to_kill <- variable_contributions_df %>% dplyr::filter(mean_residual_change_square>=0) %>% arrange(mean_residual_change_square %>% desc())
      
      current_best <- xgbcv$evaluation_log$test_rmse_mean[xgbcv$best_iteration]
      print(glue::glue("Current best is {current_best}") )

      #If none do then break out of this loop with the final model
      if(nrow(variable_contributions_df_to_kill)==0){break}
    
      #Withold that worst variable from the set and loop all over again
      kick_out <- variable_contributions_df_to_kill$variable[1] #
      print(glue::glue("I'm kicking out {kick_out}") )
      vars_to_include_pruned <- setdiff(vars_to_include_pruned,kick_out) #change vars to include by removing that one and then loop back over
      
      path_hyperparameter_search <- glue::glue("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/validation_predictions/{model_name}_testfold_{i}_lastkicked_{m}.parquet")  #had to change it from variable names because the file names got too long
      arrow::write_parquet(variable_contributions_df, path_hyperparameter_search)   
      
      
    }
    
    print(glue::glue("################################################################################################I finished pruning the model"))
    #I finished pruning the model

    #Refitting the last run just with all the data, no validation holdout
    xgboost_best <- NULL
    xgboost_best <-  xgb.train(params=pars_best,data=d_train, nrounds=xgbcv$best_iteration, verbose = 0, nthread=120)
    path_model <- glue::glue("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/models/{model_name}{i}.xgboost")
    xgb.save(xgboost_best, fname=path_model)

    p_load(rjson)
    predictions <- NULL
    predictions <- yid_test %>% 
                   mutate(y_hat=predict(xgboost_best, d_test)) %>%
                   mutate(model_name=model_name) %>%
                   mutate(path_model=path_model) %>%
                   mutate(parameters=pars_best %>% toJSON(indent=0, method="C" ) ) %>%
                   mutate(nrounds_best=xgbcv$best_iteration ) %>%
                   mutate(expected_rmse=current_best ) %>%
                   mutate(training_n=nrow(x_train) ) %>%
                   mutate(vars_to_include_n=length(vars_to_include) ) %>%
                   mutate(vars_to_include_pruned_n=length(vars_to_include_pruned) ) %>%
      
                   mutate(vars_to_include=paste(vars_to_include, collapse=";") ) %>%
                   mutate(vars_to_include_pruned=paste(vars_to_include_pruned, collapse=";") )
    
    predictions_list[[as.character(i)]] <- predictions
    
  }

    pred_all <- bind_rows(predictions_list) %>% mutate(residual=y_hat-uptake_max) 
    arrow::write_parquet(pred_all, path_predictions)

   tictoc::toc() %>% print()

}

    



```

#### BORTA VERSION

```{r, message=F, result=F, eval=F}


p_load(xgboost)
p_load(Rfast)
p_load(testit)
fit_subset_model <- function(model_name='',vars_to_include=c('')) {

  print(model_name)
  path_predictions <- glue::glue("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/test_predictions/{model_name}.parquet")
  if(file.exists(path_predictions)){
    print("Already exists, skipping")
    return()
  }    
  
  yid_all <- NULL
  xid_all <- NULL
  
  
  tictoc::tic()
  yid_all <- xyid_all %>% dplyr::select(fold, fips,fips_state, uptake_max)  #This subsets it to just our dv , plus Ids
  xid_all <- xyid_all %>% dplyr::select(fold,   fips, fips_state,one_of(vars_to_include))  #this to just the vars we want to include, plus IDs
  setdiff(vars_to_include,names(xid_all)) %>% print()
  testit::assert(length(setdiff(vars_to_include,names(xid_all)))==0) #no variables are missing
    
  #So it first loops over all 6 test sets
  predictions_list <- list()
  for(i in 1:6){

    #Fold is what we're excluding
    yid_train <- yid_all %>% dplyr::filter(!fold %in% c(i)) #this subsets it to everything but the test fold
    yid_test <- yid_all %>% dplyr::filter(fold %in% c(i))
    
    xid_train <- xid_all %>% dplyr::filter(!fold %in% c(i)) #this subsets it to everything but the test fold
    xid_test <- xid_all %>% dplyr::filter(fold %in% c(i))    
    
    #This will then do 3 fold cross validation within just the training data and splitting randomly on state
    #fips_state <- xid_train$fips_state %>% unique() %>% sample() #shuffle the list
    #cv_folds <- rep_len(1:3, length.out=length(fips_state)); names(cv_folds) <- fips_state
    #cv_folds[as.character(xid_train$fips_state)]
    #cv_folds <- rep_len(1:5, length.out=length(fips_state)); names(cv_folds) <- fips_state
    remaining_folds <- xid_train$fold %>% unique()
    
    #folds list provides a possibility to use a list of pre-defined CV folds (each element must be a vector of test fold's indices). When folds are supplied, the nfold and stratified parameters are ignored.
    Folds <- list(
        Fold1 = which(xid_train$fold==remaining_folds[1]) #There are 5 folds left to choose from, here we fit on everything but the first one
      , Fold2 = which(xid_train$fold==remaining_folds[2]) #Everything but the second one
      , Fold3 = which(xid_train$fold==remaining_folds[3])
      , Fold4 = which(xid_train$fold==remaining_folds[4])
      , Fold5 = which(xid_train$fold==remaining_folds[5])
    )
    #We further pick splits by state for CV

    y_train <- NULL; y_valid<-NULL;y_test<-NULL #Nuke everything just to make sure
    x_train <- NULL; x_valid<-NULL;x_test<-NULL
    d_train <- NULL; d_valid <- NULL; d_test <- NULL

    y_train <- yid_train %>% dplyr::select(uptake_max) 
    y_test <-  yid_test %>% dplyr::select(uptake_max)
    
    #grid <- rbind( 
    #    data.frame(max_depth=6, min_child_weight=15, subsample=1 ) #, #on median subsample 1 wins, you have to vary the other two to find slightly better outcomes
    #    #data.frame(max_depth=6, min_child_weight=15, subsample=0.9 ),
    #    #data.frame(max_depth=6, min_child_weight=15, subsample=0.8 ),
    #    #data.frame(max_depth=6, min_child_weight=15, subsample=0.7 ),
    #    #data.frame(max_depth=6, min_child_weight=15, subsample=0.6 ),
    #    #data.frame(max_depth=6, min_child_weight=15, subsample=0.5 ),
    #    #data.frame(max_depth=6, min_child_weight=15, subsample=0.4 ),
    #    #data.frame(max_depth=6, min_child_weight=15, subsample=0.3 )#,
    #    #data.frame(max_depth=6, min_child_weight=15, subsample=0.3 ),
    #    #data.frame(max_depth=6, min_child_weight=15, subsample=0.3 )
    #)
    
    pars_best <- list( 
      booster = "gbtree"
      , eta = 0.01 #getBestPars(optObj)$eta #they picked a very low learning rate #lower learning rate for the final one
      , max_depth = 6 #grid_result_best$max_depth
      , min_child_weight = 15 #grid_result_best$min_child_weight
      , subsample = 1 #grid_result_best$subsample
      , objective = "reg:squarederror"
      , eval_metric = "rmse"
    )
          
    #Iterate until vars_to_include_pruned doesn't change
    vars_to_include_pruned=vars_to_include
    for(k in 1:10){
      #We then loop over variables, kicking out whichever one contributes the most to out of sample overfitting
      x_train <- xid_train %>% dplyr::select(one_of(vars_to_include_pruned)) #our xtrain is fit to increasingly small sets of vars
      x_test <- xid_test %>% dplyr::select(one_of(vars_to_include_pruned))
      d_train <- xgb.DMatrix( x_train %>% Rfast::data.frame.to_matrix(),  label=y_train %>% Rfast::data.frame.to_matrix(col.names=T )); 
      d_test <- xgb.DMatrix( x_test %>% Rfast::data.frame.to_matrix(),  label=y_test %>% Rfast::data.frame.to_matrix(col.names=T ));
      
      variable_contributions_list <- list()
      for(m in 1:(10)){ #Number of shuffles to try
          print(m)
          x_train_shuffled <- bind_cols(x_train,x_train %>% sample_frac(1) %>% rename_all(~paste0(., "_shuffled")) )
          columns_to_sample_perc <- runif(1,.25,1)
          x_train_shuffled <- x_train_shuffled[,runif(ncol(x_train_shuffled))<columns_to_sample_perc]
          d_train_shuffled <- xgb.DMatrix( x_train_shuffled %>% Rfast::data.frame.to_matrix(),  label=y_train %>% Rfast::data.frame.to_matrix(col.names=T )); 
    
          xgbcv <- NULL
          xgbcv <- xgb.cv(
            params = pars_best
            , data = d_train_shuffled
            , nround = 2000
            , folds = Folds
            , prediction = TRUE
            , showsd = TRUE
            , early_stopping_rounds = 10
            , maximize = F
            , verbose = 0
            ,nthread=128
            ,callbacks = list(cb.cv.predict(save_models = TRUE))
          )    
    
          for(j in 1:5){
            shap_marginal <- predict(xgbcv$models[[j]],  xgb.DMatrix( x_train_shuffled[Folds[j] %>% unlist(),] %>% Rfast::data.frame.to_matrix() ) , predcontrib=T  ) #get shap values for model j on validation hold out j
            BIAS0=shap_marginal[,ncol(shap_marginal)][1] #That last column is the bias
            shap_marginal <- shap_marginal[,-ncol(shap_marginal)]
            colnames(shap_marginal) <- colnames(x_train_shuffled)
            y <-  y_train[Folds[j] %>% unlist(),]
            y$y_hat <- rowSums(shap_marginal) + BIAS0 #Compute the Yhat for the model at each observation
            y$residual <- y$y_hat- y$uptake_max #calculate the residual
            residual_new <- y$residual - shap_marginal #What would the residual be if we subtracted off the contribution from that variable?
            residual_change_square <- y$residual^2-residual_new^2 #Did that make the residual bigger or smaller? #Changed this to reduction in square error. Otherwise we could flip neg and not know it.
            variable_contributions_list[[paste(m,j)]] <- residual_change_square  %>% as.data.frame()
          }
        }
        #current_best <- xgbcv$evaluation_log$test_rmse_mean[xgbcv$best_iteration]
        variable_contributions_df <- bind_rows(variable_contributions_list)  %>% #ok this is now the change in mean squared error from that variable for every observation in every validation set
                                     colMeans(na.rm=T) %>% #this is now the mean change in mean squared error
                                     #round() %>% #apparently the changes to mean squared error are quite small
                                     #group_by(variable) %>% 
                                     #  summarise(change_to_residual_mean=mean(change_to_residual) %>% round(4)) %>% #This is meaning again over the folds, is that what we want to do?
                                     # ungroup() %>% 
                                     as.data.frame() %>% rownames_to_column(var="variable") %>% rename(mean_residual_change_square='.') %>%
                                     arrange(mean_residual_change_square) %>% 
                                     mutate(shuffled=variable %>% stringr::str_detect("_shuffled$") %>% as.numeric())
        
        variable_contributions_df_tokeep <- variable_contributions_df %>% filter(cumsum(shuffled)==0)
        if( all(variable_contributions_df_tokeep$variable==vars_to_include_pruned )){ #if the keep variable set doesn't change break out of this particular for loop
          print("Done pruning #####"); next
        }
        vars_to_include_pruned <- variable_contributions_df_tokeep$variable
    }
    
    
      
      
                                   mutate(test_fold=i) %>%
                                   mutate(pruning=m) %>%
                                   mutate(vars_to_include_n=length(vars_to_include) ) %>%
                                   mutate(vars_to_include_pruned_n=length(vars_to_include_pruned) ) %>%
                      
                                   mutate(vars_to_include=paste(vars_to_include, collapse=";") ) %>%
                                   mutate(vars_to_include_pruned=paste(vars_to_include_pruned, collapse=";") ) %>%
                                   mutate(current_validation_rmse=current_best )

      variable_contributions_df_to_kill <- variable_contributions_df %>% dplyr::filter(mean_residual_change_square>=0) %>% arrange(mean_residual_change_square %>% desc())
      
      current_best <- xgbcv$evaluation_log$test_rmse_mean[xgbcv$best_iteration]
      print(glue::glue("Current best is {current_best}") )

      #If none do then break out of this loop with the final model
      if(nrow(variable_contributions_df_to_kill)==0){break}
    
      #Withold that worst variable from the set and loop all over again
      kick_out <- variable_contributions_df_to_kill$variable[1] #
      print(glue::glue("I'm kicking out {kick_out}") )
      vars_to_include_pruned <- setdiff(vars_to_include_pruned,kick_out) #change vars to include by removing that one and then loop back over
      
      path_hyperparameter_search <- glue::glue("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/validation_predictions/{model_name}_testfold_{i}_lastkicked_{m}.parquet")  #had to change it from variable names because the file names got too long
      arrow::write_parquet(variable_contributions_df, path_hyperparameter_search)   
      
      
    }
    
    print(glue::glue("################################################################################################I finished pruning the model"))
    #I finished pruning the model

    #Refitting the last run just with all the data, no validation holdout
    xgboost_best <- NULL
    xgboost_best <-  xgb.train(params=pars_best,data=d_train, nrounds=xgbcv$best_iteration, verbose = 0, nthread=120)
    path_model <- glue::glue("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/models/{model_name}{i}.xgboost")
    xgb.save(xgboost_best, fname=path_model)

    p_load(rjson)
    predictions <- NULL
    predictions <- yid_test %>% 
                   mutate(y_hat=predict(xgboost_best, d_test)) %>%
                   mutate(model_name=model_name) %>%
                   mutate(path_model=path_model) %>%
                   mutate(parameters=pars_best %>% toJSON(indent=0, method="C" ) ) %>%
                   mutate(nrounds_best=xgbcv$best_iteration ) %>%
                   mutate(expected_rmse=current_best ) %>%
                   mutate(training_n=nrow(x_train) ) %>%
                   mutate(vars_to_include_n=length(vars_to_include) ) %>%
                   mutate(vars_to_include_pruned_n=length(vars_to_include_pruned) ) %>%
      
                   mutate(vars_to_include=paste(vars_to_include, collapse=";") ) %>%
                   mutate(vars_to_include_pruned=paste(vars_to_include_pruned, collapse=";") )
    
    predictions_list[[as.character(i)]] <- predictions
    
  }

    pred_all <- bind_rows(predictions_list) %>% mutate(residual=y_hat-uptake_max) 
    arrow::write_parquet(pred_all, path_predictions)

   tictoc::toc() %>% print()

}




```

#### Validatoin Performance

```{r, eval=F}

validation_predictions <- arrow::open_dataset("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/validation_predictions/")  %>% dplyr::collect()
dim(validation_predictions)

validation_predictions %>% mutate(vars_to_include_nchar=nchar(vars_to_include)) %>% dplyr::filter(vars_to_include_nchar==max(vars_to_include_nchar)) %>% View()
validation_predictions %>% mutate(vars_to_include_nchar=nchar(vars_to_include)) %>% dplyr::filter(vars_to_include_nchar==max(vars_to_include_nchar))  %>% mutate(variable= variable %>% fct_reorder(change_to_residual_mean)) %>% arrange(variable)  %>%
ggplot(aes(x=change_to_residual_mean, y=variable)) + geom_boxplot() + theme(legend.position = "none")

#Nope I'm an idiot, by definition that would have to be true
validation_predictions %>% mutate(vars_to_include_nchar=nchar(vars_to_include)) %>% dplyr::filter(vars_to_include_nchar==max(vars_to_include_nchar))  %>% 
  dplyr::filter(fold==3) %>%
  group_by(variable) %>% 

  summarise(min=min(mean_residual_change_square)  %>% round(8), mean=mean(mean_residual_change_square) %>% round(8), max=max(mean_residual_change_square)  %>% round(8), turns_negative=min>=0 & max<=0) %>% View()

validation_predictions %>% 
  mutate(variable = variable %>% fct_reorder(mean_residual_change_square)) %>%
  ggplot(aes(x=mean_residual_change_square, y=variable)) + geom_boxplot() #it looks like if you don't vary other things then no subsampling is preferred

#Ok so this shows me that you can get bad runs that screw up everything and flip signs
validation_predictions %>% 
  dplyr::filter(fold==1) %>%
  group_by(variable) %>%
    mutate(ever_flips=max(mean_residual_change_square)>0 & min(mean_residual_change_square)<0) %>%
  ungroup() %>%
  dplyr::filter(ever_flips) %>% #These are the ones that ever changed sign.
  #filter(variable=="white_perc") %>%
  mutate(variable= variable %>% fct_reorder(pruning,.fun=max))  %>% 
  ggplot(aes(x=pruning, y=mean_residual_change_square, color=variable))  +
  geom_hline(yintercept=0, color="black") + geom_line() +
  theme(legend.position = "none") +
  facet_wrap(~variable,scales="free_y") 
  #ylim(-0.00005,0.00005)
  #it looks like if you don't vary other things then no subsampling is preferred

#Always make it worse
validation_predictions %>% 
  dplyr::filter(fold==1) %>%
  group_by(variable) %>%
    mutate(ever_flips=max(mean_residual_change_square)>0 & min(mean_residual_change_square)>0) %>%
  ungroup() %>%
  dplyr::filter(ever_flips) %>% #These are the ones that ever changed sign.
  mutate(variable= variable %>% fct_reorder(pruning,.fun=max))  %>% 
  #filter(variable=="white_perc") %>%
  ggplot(aes(x=pruning, y=mean_residual_change_square, color=variable))  +
  geom_hline(yintercept=0, color="black") + geom_line() +
  theme(legend.position = "none") +
  facet_wrap(~variable,scales="free_y")


#Always make it better
validation_predictions %>% 
  dplyr::filter(fold==1) %>%
  group_by(variable) %>%
    mutate(ever_flips=max(mean_residual_change_square)<0 & min(mean_residual_change_square)<0) %>%
  ungroup() %>%
  dplyr::filter(ever_flips) %>% #These are the ones that ever changed sign.

  #filter(variable=="white_perc") %>%
  ggplot(aes(x=pruning, y=mean_residual_change_square, color=variable))  +
  geom_hline(yintercept=0, color="black") + geom_line() +
  theme(legend.position = "none") +
  facet_wrap(~variable,scales="free_y")

#http://www.sthda.com/english/articles/35-statistical-machine-learning-essentials/141-cart-model-decision-tree-essentials/
#p_load(party)
#set.seed(123)
#p_load(caret)
#model <- caret::train(
#  Score ~ min_child_weight + subsample + max_depth, data = validation_predictions, method = "ctree2",
#  trControl = trainControl("cv", number = 10),
#  tuneGrid = expand.grid(maxdepth = 5, mincriterion = 0.95 )
#  )
#plot(model$finalModel)


```

# Step 6: Propose an Abblation and Interrogation Strategy

Given a model provides a certain level of performance, we want to go
further and decompose that performance into explainable components
related to features, hyperparameters, or other decisions. Feature
ablation is the practice of removing access to features and gauging
changes in model performance. The process isn't straightforward. For
starters, there are $2^k$ unique subsets of k features that we could
select to hold out which is computationally infeasible. Second,
different sets of features can have comparable average performance but
different distributions across observations.

We consider three strategies. The first is theoretical, we group
features by their stated or intended topic, e.g. TrumpVote2016 and
TrumpVote2020 should be grouped because both literally measure votes and
are intended to measure political preferences and behavior. The second
is an appeal to unique bivariate information (correlation or mutual
information), e.g. TrumpVote2016 and Percent With a Bachelor's Degree
should be grouped together because they tend to vary together and so
might represent overlapping redundant information. The third is an
appeal to the work they perform in explaining our specific outcome, e.g.
TrumpVote2020 and PercentWhite should be group because conditioning on
either produces similar shifts in predictions along with other known
features.

Each of these strategies tells us something different about our model's
performance. The theoretically motivated strategy tells us about how the
real world concepts relate to the outcome, but ignores the slippage
between the values recorded and the latent real world concept it is
intended to proxy for. The unique information strategy privileges
heterogeneity, arranging features by how orthogonal they are in their
original projections. That assumes the original projection was the right
or a good one for our particular problem. The work motivated strategy is
the other extreme, arranging features by their similarity within our
specific modeling strategy. That assumes that our newly chosen
projection is the right or a good one. The claim to validity here lies
in our theoretical motivation of choice of model, buttressed by the
demonstration of predictive performance.

Achen (2015), you can't know a priori how a feature will be used by an
algorithm. Even in OLS, you can't 'sign the bias' by excluding a feature
because its roll depends on the conditional correlation with the full
rest of the feature vector. (green)

We can't compute 2\^n combinations of features, but we can generate a
reasonably sized random sample. We fit 100k regression trees, of depth
6, each with a different random sample of 10 variables and a different
random sample of 66% of the observations. We then calculate the shap
values for each feature-interaction-observation combination, and we end
up with a reasonable estimate of how our outcome variable variables in
each subspace and how each pair of features work together to produce
that result. We can then group features together based how similar the
work is they do.

```{r}


y_train <- NULL; y_valid<-NULL;y_test<-NULL #Nuke everything just to make sure
x_train <- NULL; x_valid<-NULL;x_test<-NULL
d_train <- NULL; d_valid <- NULL; d_test <- NULL


vars_to_include <- var_sets[all_sets] %>% unlist()

p_load(xgboost)
p_load(Rfast)
p_load(testit)

yid_all <- NULL
xid_all <- NULL

yid_all <- xyid_all %>% dplyr::select(fold, fips,fips_state, uptake_max)  #This subsets it to just our dv , plus Ids
xid_all <- xyid_all %>% dplyr::select(fold,   fips, fips_state,one_of(vars_to_include))  #this to just the vars we want to include, plus IDs
setdiff(vars_to_include,names(xid_all)) %>% print()
testit::assert(length(setdiff(vars_to_include,names(xid_all)))==0) #no variables are missing
    
xid_train <- xid_all

#Fold is what we're excluding
yid_train <- yid_all #%>% dplyr::filter(!fold %in% c(i)) #this subsets it to everything but the test fold
#yid_test <- yid_all #%>% dplyr::filter(fold %in% c(i))

y_train <- yid_train %>% dplyr::select(uptake_max) 
#y_test <-  yid_test %>% dplyr::select(uptake_max)

#We then loop over variables, kicking out whichever one contributes the most to out of sample overfitting
x_train <- xid_train %>% dplyr::select(one_of(vars_to_include)) #our xtrain is fit to increasingly small sets of vars
#x_test <- xid_test %>% dplyr::select(one_of(vars_to_include))
d_train <- xgb.DMatrix( x_train %>% Rfast::data.frame.to_matrix(),  label=y_train %>% Rfast::data.frame.to_matrix(col.names=T )); 
#d_test <- xgb.DMatrix( x_test %>% Rfast::data.frame.to_matrix(),  label=y_test %>% Rfast::data.frame.to_matrix(col.names=T ));    

#This takes no time at all 
#library(randomForestSRC)
#tictoc::tic()
#  rf <- rfsrc(formula = uptake_max ~ . , data= cbind(x_train,  y_train) %>% as.data.frame() , ntree = 100, na.action ="na.impute")
#rf
#tictoc::toc()
#library(Metrics)
#Metrics::rmse(rf$predicted.oob , y_train$uptake_max) #Actually has a pretty low rmse 0.052, ah because it's using all of it, not cross validating with the folds

#Something is wrong with xgboost
#RF https://xgboost.readthedocs.io/en/latest/tutorials/rf.html
pars_rf <- list( 
  booster = "gbtree"
  , num_parallel_tree=99999 #this matters and you really do need to up the n to make sure it settles out #lol Invalid Parameter format for num_parallel_tree expect int but value='1e+05'
  , eta = 1
  , colsample_bytree=sqrt(ncol(d_train))/ncol(d_train) # colsample_bynode
  , max_depth = 6 #grid_result_best$max_depth
  #, min_child_weight = 15 #grid_result_best$min_child_weight
  , subsample = 0.66 #grid_result_best$subsample
  , objective = "reg:squarederror"
  , eval_metric = "rmse"
)

#We don't really need to do CV because we don't care about how it performs. We can see it's a little worse, we' just using this as a fast in sample interaction check
tictoc::tic()
xgbcv <- NULL
xgbcv <- xgb.train(
  params = pars_rf
  , data = d_train
  , nrounds = 1
  #, folds = Folds
  #, prediction = TRUE
  #, showsd = TRUE
  #, early_stopping_rounds = 10
  #, maximize = F
  , verbose = 0
  ,nthread=128
  #,callbacks = list(cb.cv.predict(save_models = TRUE))
 )    #0.074622 the random forest isn't too bad 0.074
xgbcv     

```

Marginal contribution

```{r}
#So one way to think about this is marginal effects, we group variables by how they push the same observations in the same direction by the same amount
tictoc::toc() #4 seconds for 1k
shap_marginal <- predict(xgbcv,  d_train, predcontrib=T  )[,-105] #[,-(ncol(x_train)+1)] #last column is the bias
colnames(shap_marginal) <- colnames(x_train)
dim(shap_marginal)
cor(shap_marginal[,'white_perc'] , shap_marginal[,'black_perc']) #-0.07550175
 Heatmap(shap_marginal %>% cor(), row_dend_reorder = TRUE, column_dend_reorder = TRUE, column_names_rot = 45,
     #row_names_max_width = max_text_width(rownames(feature_interactions_matrix_cor) ), 
     column_names_gp=  gpar(fontsize = 8),
     row_names_gp=  gpar(fontsize = 8),
     clustering_method_rows="ward.D2",
     clustering_method_columns="ward.D2"
 )
```

Conditional contribution

```{r}

#Or we might wan tto think about this as conditional effects, we group variables when their effect conditional on other things is similar. So after we condition on wealth, what things point the same way
#This is a second order effect? Comparing each bivariate interaction and making sure they point the same way?
#That top left corner is basically race, recent politics, and urbanity. Once you condition out wealth, all those things basically capture the same thing is what this is saying. That actually makes a lot of sense to me.
#The bottom right is basically wealth lots of travel, education, entertainment
#The only thing is correlations are super weak, so our distance tree is very shallow.
tictoc::tic()
shap_interaction <- predict(xgbcv,  d_train, predinteraction=T  )
tictoc::toc() #1 min for 1k, 1.7min for 2k, so sublinearly
#We can cluster observations by how the features and feature interactions think about them
#And we can cluster features by how they interact with each other
n_features=dim(shap_interaction)[2]-1 #the last one is the bias I think
n_obs=dim(shap_interaction)[1]
#shap_interaction[1:n_obs,1,] #This is feature 1's interaction with every other variable for every obs
#shap_interaction[1:n_obs,1,] %>% as.vector()
#shap_interaction[1:n_obs,1,] %>% t()
shape <- shap_interaction[1,,] %>% lower.tri(diag = F)
#shap_interaction[1,,][shape]
#shap_interaction[1:n_obs,1,1:n_features] %>% dim() #this is the the first feature's contribution in interaction with every other feature for every obs
#temp <- shap_interaction[1:n_obs,1,1:n_features]  %>% as.data.frame()
#colnames(temp) <- colnames(x_train)
#summary(temp$gdp_all_industry_total)
#summary(temp$gdp_private_industries)

feature_interactions_matrix <- do.call(rbind, lapply(1:n_features, FUN=function(i){ shap_interaction[1:n_obs,i,1:n_features] %>% as.vector() } ) )
dim(feature_interactions_matrix) #This is feature x (obs x interaction)

#This begs the question about third order interactions, but I guess that's what running full models is for. This gets us started as far as clustering variables into groups

feature_interactions_matrix_t <- feature_interactions_matrix %>% t(); colnames(feature_interactions_matrix_t) <- colnames(x_train)
dim(feature_interactions_matrix_t)
cor(feature_interactions_matrix_t[,'white_perc'] , feature_interactions_matrix_t[,'black_perc']) #0.04599981

#feature_interactions_matrix_cor <- feature_interactions_matrix %>% t() %>% cor()
#diag(feature_interactions_matrix_cor) <- NA
#install.packages('heatmaply')

#library(devtools)
#install_github("jokergoo/ComplexHeatmap")
#Ok I think I understand this now
#When they're close by, they tend to push in the same direction
#When they're far apart they tend to push in opposite directions, for the same observations
#So for example, top left of this heatmap is trump2020 also known as percent white or percent black
#Bottom right of this map is wealth of a county also known as arts per capita, amount science, etc.
#So these are people who are trump voters but also have enough money or wealth to get vaccinated. Clustering first on similarity to remove redundancy and then picking clusters on difference to provide interaction
#That race/vs trump2020 cluster, you can see that race doesn't negatively correlated with much, it's mostly zeros, its trump that negatively correlates with a lot, although black percent does too a bit.
library(ComplexHeatmap)
Heatmap(feature_interactions_matrix_t %>% cor(), row_dend_reorder = TRUE, column_dend_reorder = TRUE, column_names_rot = 45,
       #row_names_max_width = max_text_width(rownames(feature_interactions_matrix_cor) ), 
       column_names_gp=  gpar(fontsize = 8),
       row_names_gp=  gpar(fontsize = 8),
       clustering_method_rows="ward.D2",
       clustering_method_columns="ward.D2",
       row_names_max_width=max_text_width(
  rownames(feature_interactions_matrix_t), 
  gp = gpar(fontsize = 8)
)
)

#library(heatmaply)
#heatmaply_cor(
#    feature_interactions_matrix_cor,
#    xlab = "Features",
#    ylab = "Features",
#    k_col = 2,
#    k_row = 2
#  )

feature_interactions_matrix_cor_dist <- feature_interactions_matrix_t %>% cor() %>% dist()
#summary(feature_interactions_matrix_cor_dist)
hc_feature_interactions_matrix <- hclust(feature_interactions_matrix_cor_dist, method="ward.D2")
plot(hc_feature_interactions_matrix)
   

```

```{r}

library(viridis)
xyid_all %>%
 dplyr::select(donaldjtrump_2020,black_perc, uptake_max) %>%
 mutate(donaldjtrump_2020=donaldjtrump_2020 %>% round(1)) %>%
 mutate(black_perc=black_perc %>% round(1)) %>%
 group_by(donaldjtrump_2020,black_perc) %>%
 summarise(uptake_max=mean(uptake_max, na.rm=T)) %>%
  ggplot( aes(black_perc, donaldjtrump_2020, fill = uptake_max))+
 geom_raster() + scale_fill_viridis_c(option = "A") + theme_bw()

```
